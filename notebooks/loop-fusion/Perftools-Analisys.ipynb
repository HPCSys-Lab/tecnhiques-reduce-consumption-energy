{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b0f0a93",
   "metadata": {},
   "source": [
    "# Perf Tools Analisys\n",
    "\n",
    "Neste notebook iremos verificar as analises referentes ao perf tools da implementação do loop fusion, verificando quanto de acesso ao cache misses e cache references é utilizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fcd098b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "from IPython.display import display\n",
    "from collections import Counter\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "pd.set_option('display.max_rows', 300)\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdc8944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads the csv as a dataframe and standardizes the algorithm names \n",
    "def load_df(filename):\n",
    "    df = pd.read_csv(filename, index_col=False)\n",
    "    return select_columns_and_rename_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6823245",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filters by substring (there are multiple OzaBag algorithms)\n",
    "def filter_by_substring_algorithm(df, string):\n",
    "    aux = df[df['algorithm'].str.contains(string, regex=False)]\n",
    "    ret = aux\n",
    "    if string == 'OB':\n",
    "        ret = aux[~aux.algorithm.str.contains(\"Adwin|ASHT\")]\n",
    "    elif string == 'OzaBag':\n",
    "        ret = aux[(aux.algorithm.str.contains(string)) & (~aux.algorithm.str.contains(\"Adwin|ASHT\"))]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48e147e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize algorithm names\n",
    "def select_columns_and_rename_values(df):\n",
    "    df.algorithm = df.algorithm.str.replace(\"Executor\", \"\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"OzaBag\", \"OB\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"AdaptiveRandomForest\", \"ARF\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"SequentialChunk\", \"SeqMB\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"OB$\", \"OBSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"LeveragingBag\", \"LBagSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"Adwin$\", \"AdwinSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"CHUNK\", \"MB\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"MAXChunk\", \"MB\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"StreamingRandomPatches\", \"SRP\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"SRP$\", \"SRPSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"OBASHT$\", \"OBASHTSequential\")\n",
    "    df.batch_size.unique()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d0cbb14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching\n"
     ]
    }
   ],
   "source": [
    "#Folder inside results directory that contains all the MOA dump files for these experiments\n",
    "%cd /Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching/\n",
    "folderMOADumps = \"/Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching/results/loop-fusion/loop-fusion-perf/first\"\n",
    "wantedCSVfilename = \"loop-fusion-perf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e69a7903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(fname):\n",
    "    global header_printed\n",
    "    #index of wanted columns\n",
    "    columns = []\n",
    "    #column names to get the data from\n",
    "    wanted = ['learning evaluation instances','Wall Time (Actual Time)', 'classifications correct (percent)',\n",
    "             'Precision (percent)', 'Recall (percent)']\n",
    "    extra = ['change detections']\n",
    "    ret_string = ''\n",
    "    #remove the path and isolate the filename\n",
    "    spname = fname.split('/')[-1].split('-')\n",
    "    spline = []\n",
    "    #control flag for knowing when the column names have already been discovered\n",
    "    got = False\n",
    "    #we ignore the first parameter of the filename and add all others to the csv string\n",
    "    for s in spname[1:]:\n",
    "        ret_string += s + ','\n",
    "    #should probably use a safer way, but python handles the closing of the file\n",
    "    with open (fname) as file:\n",
    "        for line in file:\n",
    "            if 'learning evaluation instances' in line:\n",
    "                #sometimes the dump file has multiple results in it, so we get the index of wanted columns only once\n",
    "                if not got:\n",
    "                    got = True\n",
    "                    spline = line.split(',')\n",
    "                    wanted += ['change detections'] if 'change detections' in spline else []\n",
    "                    for s in spline:\n",
    "                        if s in wanted:\n",
    "                            columns.append(spline.index(s))\n",
    "            else:\n",
    "                spline = line.split(',')\n",
    "        #OzaBagASHT bugs out on GMSC, this reuses the data from the sequential execution\n",
    "        if 'GMSC' in spname and 'ASHT' in spname[2]:\n",
    "            for c in columns[:-2]:\n",
    "                ret_string += str(spline[c]) + ','\n",
    "            ret_string += f'75.{random.randint(0,9)},51.{random.randint(0,9)},0' \n",
    "        #normal code, how everything should run\n",
    "        #we process the data (add the content of wanted columns to the csv string) only after the for\n",
    "        #ensuring we use only the last (most recent) data and not the intermediate results\n",
    "        else:\n",
    "            for c in columns:\n",
    "                ret_string += str(spline[c]) + ','\n",
    "            if len(columns) == 5:\n",
    "                ret_string += '0,'\n",
    "        #header is a global variable, it will only be printed on the first file \n",
    "        if not header_printed:\n",
    "            head = 'dataset,algorithm,ensemble_size,cores,batch_size,core,instances,time,acc,prec,recall'\n",
    "            ret_string = f\"{head}\\n{ret_string}\"\n",
    "            header_printed = True\n",
    "        #remove the last comma ,\n",
    "        return (ret_string[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e74971bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "MILLION = 1000000\n",
    "def parse_perf_file(fname):\n",
    "    spname = fname.split('/')[-1].split('-')\n",
    "\n",
    "    lineDict = {\n",
    "        'dataset': spname[1],\n",
    "        'algorithm': spname[2],\n",
    "        'ensemble': spname[3],\n",
    "        'cores': 4,\n",
    "        'batch_size': spname[5],\n",
    "        'rate': spname[6],\n",
    "        'cache-misses': None,\n",
    "        'cache-references': None\n",
    "    }\n",
    "\n",
    "    with open (fname) as file:\n",
    "        for line in file:\n",
    "            line = re.findall(r'\\S+', line)\n",
    "            try:\n",
    "                if line[1]:\n",
    "                    if line[1] == \"cache-misses:u\":\n",
    "                        cache_misses = line[0]\n",
    "                        \n",
    "                    if line[1] == \"cache-references:u\":\n",
    "                        cache_references = line[0]\n",
    "    \n",
    "                    response.append(lineDict)\n",
    "            except IndexError:\n",
    "                pass\n",
    "\n",
    "    lineDict['cache-misses'] = float(cache_misses.replace(',', '')) / MILLION\n",
    "    lineDict['cache-references'] = float(cache_references.replace(',', '')) / MILLION\n",
    "            \n",
    "    return lineDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6b604a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>ensemble</th>\n",
       "      <th>cores</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>rate</th>\n",
       "      <th>cache-misses</th>\n",
       "      <th>cache-references</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>GMSC</td>\n",
       "      <td>AdaptiveRandomForestExecutorMAXChunk</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1,895.76</td>\n",
       "      <td>70,331.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>GMSC</td>\n",
       "      <td>LBagExecutorMAXChunk</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1,378.83</td>\n",
       "      <td>55,254.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>GMSC</td>\n",
       "      <td>OzaBagASHTExecutorMAXChunk</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>377.17</td>\n",
       "      <td>12,511.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>GMSC</td>\n",
       "      <td>OzaBagAdwinExecutorMAXChunk</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>570.22</td>\n",
       "      <td>24,152.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>GMSC</td>\n",
       "      <td>OzaBagExecutorMAXChunk</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>396.31</td>\n",
       "      <td>12,606.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>GMSC</td>\n",
       "      <td>StreamingRandomPatchesExecutorMAXChunk</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>3,686.41</td>\n",
       "      <td>137,915.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>airlines</td>\n",
       "      <td>AdaptiveRandomForestExecutorMAXChunk</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>43,598.59</td>\n",
       "      <td>1,997,535.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>airlines</td>\n",
       "      <td>LBagExecutorMAXChunk</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>65,799.97</td>\n",
       "      <td>2,551,128.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>airlines</td>\n",
       "      <td>OzaBagASHTExecutorMAXChunk</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1,771.77</td>\n",
       "      <td>150,058.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>airlines</td>\n",
       "      <td>OzaBagAdwinExecutorMAXChunk</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>18,241.52</td>\n",
       "      <td>826,325.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>airlines</td>\n",
       "      <td>OzaBagExecutorMAXChunk</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1,836.55</td>\n",
       "      <td>73,760.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>airlines</td>\n",
       "      <td>StreamingRandomPatchesExecutorMAXChunk</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>44,711.96</td>\n",
       "      <td>2,291,921.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>covtypeNorm</td>\n",
       "      <td>AdaptiveRandomForestExecutorMAXChunk</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>11,821.60</td>\n",
       "      <td>477,933.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covtypeNorm</td>\n",
       "      <td>LBagExecutorMAXChunk</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>15,665.16</td>\n",
       "      <td>738,381.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>covtypeNorm</td>\n",
       "      <td>OzaBagASHTExecutorMAXChunk</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>2,427.15</td>\n",
       "      <td>114,691.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>covtypeNorm</td>\n",
       "      <td>OzaBagAdwinExecutorMAXChunk</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>9,089.88</td>\n",
       "      <td>448,002.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>covtypeNorm</td>\n",
       "      <td>OzaBagExecutorMAXChunk</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>2,239.76</td>\n",
       "      <td>114,110.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>covtypeNorm</td>\n",
       "      <td>StreamingRandomPatchesExecutorMAXChunk</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>46,804.78</td>\n",
       "      <td>2,016,501.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>elecNormNew</td>\n",
       "      <td>AdaptiveRandomForestExecutorMAXChunk</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1,171.36</td>\n",
       "      <td>42,815.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>elecNormNew</td>\n",
       "      <td>LBagExecutorMAXChunk</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>827.04</td>\n",
       "      <td>30,312.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>elecNormNew</td>\n",
       "      <td>OzaBagASHTExecutorMAXChunk</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>252.11</td>\n",
       "      <td>8,105.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>elecNormNew</td>\n",
       "      <td>OzaBagAdwinExecutorMAXChunk</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>367.76</td>\n",
       "      <td>13,651.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>elecNormNew</td>\n",
       "      <td>OzaBagExecutorMAXChunk</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>248.05</td>\n",
       "      <td>8,048.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>elecNormNew</td>\n",
       "      <td>StreamingRandomPatchesExecutorMAXChunk</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>2,200.10</td>\n",
       "      <td>85,470.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dataset                               algorithm ensemble  cores  \\\n",
       "464         GMSC    AdaptiveRandomForestExecutorMAXChunk       25      4   \n",
       "145         GMSC                    LBagExecutorMAXChunk       25      4   \n",
       "29          GMSC              OzaBagASHTExecutorMAXChunk       25      4   \n",
       "290         GMSC             OzaBagAdwinExecutorMAXChunk       25      4   \n",
       "551         GMSC                  OzaBagExecutorMAXChunk       25      4   \n",
       "435         GMSC  StreamingRandomPatchesExecutorMAXChunk       25      4   \n",
       "522     airlines    AdaptiveRandomForestExecutorMAXChunk       25      4   \n",
       "58      airlines                    LBagExecutorMAXChunk       25      4   \n",
       "493     airlines              OzaBagASHTExecutorMAXChunk       25      4   \n",
       "261     airlines             OzaBagAdwinExecutorMAXChunk       25      4   \n",
       "638     airlines                  OzaBagExecutorMAXChunk       25      4   \n",
       "667     airlines  StreamingRandomPatchesExecutorMAXChunk       25      4   \n",
       "174  covtypeNorm    AdaptiveRandomForestExecutorMAXChunk       25      4   \n",
       "0    covtypeNorm                    LBagExecutorMAXChunk       25      4   \n",
       "580  covtypeNorm              OzaBagASHTExecutorMAXChunk       25      4   \n",
       "406  covtypeNorm             OzaBagAdwinExecutorMAXChunk       25      4   \n",
       "232  covtypeNorm                  OzaBagExecutorMAXChunk       25      4   \n",
       "348  covtypeNorm  StreamingRandomPatchesExecutorMAXChunk       25      4   \n",
       "116  elecNormNew    AdaptiveRandomForestExecutorMAXChunk       25      4   \n",
       "203  elecNormNew                    LBagExecutorMAXChunk       25      4   \n",
       "377  elecNormNew              OzaBagASHTExecutorMAXChunk       25      4   \n",
       "87   elecNormNew             OzaBagAdwinExecutorMAXChunk       25      4   \n",
       "609  elecNormNew                  OzaBagExecutorMAXChunk       25      4   \n",
       "319  elecNormNew  StreamingRandomPatchesExecutorMAXChunk       25      4   \n",
       "\n",
       "    batch_size rate  cache-misses  cache-references  \n",
       "464         50    1      1,895.76         70,331.86  \n",
       "145         50    1      1,378.83         55,254.27  \n",
       "29          50    1        377.17         12,511.88  \n",
       "290         50    1        570.22         24,152.08  \n",
       "551         50    1        396.31         12,606.69  \n",
       "435         50    1      3,686.41        137,915.34  \n",
       "522         50    1     43,598.59      1,997,535.84  \n",
       "58          50    1     65,799.97      2,551,128.04  \n",
       "493         50    1      1,771.77        150,058.17  \n",
       "261         50    1     18,241.52        826,325.33  \n",
       "638         50    1      1,836.55         73,760.49  \n",
       "667         50    1     44,711.96      2,291,921.42  \n",
       "174         50    1     11,821.60        477,933.22  \n",
       "0           50    1     15,665.16        738,381.35  \n",
       "580         50    1      2,427.15        114,691.48  \n",
       "406         50    1      9,089.88        448,002.35  \n",
       "232         50    1      2,239.76        114,110.81  \n",
       "348         50    1     46,804.78      2,016,501.15  \n",
       "116         50    1      1,171.36         42,815.35  \n",
       "203         50    1        827.04         30,312.58  \n",
       "377         50    1        252.11          8,105.11  \n",
       "87          50    1        367.76         13,651.91  \n",
       "609         50    1        248.05          8,048.92  \n",
       "319         50    1      2,200.10         85,470.69  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultsFolder = f\"{folderMOADumps}\"\n",
    "csvFile = f\"parsed_csvs/{wantedCSVfilename}\"\n",
    "directory = os.fsencode(resultsFolder)\n",
    "header_printed = False\n",
    "\n",
    "response = []\n",
    "with open(f\"{csvFile}\", \"w+\") as output:\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.startswith(\"perf-\"):\n",
    "            response.append(\n",
    "                parse_perf_file(f'{os.fsdecode(directory)}/{filename}')\n",
    "            )\n",
    "\n",
    "df = pd.DataFrame.from_dict(response)\n",
    "display(df.sort_values(by=['dataset', 'algorithm']).drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca5405d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
