{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To use this notebook, make sure you cd into the main folder of the cloned repository in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching\n",
      "/Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching/results\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching\n",
    "%mkdir -p parsed_csvs figures\n",
    "%cd results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folders inside results directory that contains all the MOA dump files for these experiments\n",
    "\n",
    "### Ideally results should be in this hierarchy:\n",
    "\n",
    "\n",
    "```bash\n",
    "├─ results\n",
    "│   ├── Energy\n",
    "        ├── pi\n",
    "        │   ├── get_rates\n",
    "        │   └── socket\n",
    "        ├── vostro\n",
    "        │   ├── get_rates\n",
    "        │   └── socket\n",
    "        └── xeon\n",
    "            ├── get_rates\n",
    "            └── socket\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## folder variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should probably find automatically...\n",
    "moaDumpFolders = [\"18-01-2022/600/600/first\"]\n",
    "wantedCSVfilename = [\"pi-600x600-get_rates.csv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrating the workload generator based on maximum throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "from IPython.display import display\n",
    "from collections import Counter\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "pd.set_option('display.max_rows', 300)\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Parsing preliminary results to find maximum rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_folder_to_file(folder, outfilename):\n",
    "    directory = os.fsencode(folder)\n",
    "    header_printed = False\n",
    "    with open(f\"{outfilename}\", \"w+\") as output:\n",
    "        output.write('dataset,algorithm,ensemble_size,cores,batch_size,rate,instances,time,acc,prec,recall,change\\n')\n",
    "        for file in os.listdir(directory):\n",
    "            filename = os.fsdecode(file)\n",
    "            if filename.startswith(\"dump-\"): \n",
    "                s = parse(f'{os.fsdecode(directory)}/{filename}')\n",
    "                output.write(f\"{s}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(fname):\n",
    "    columns = []\n",
    "    wanted = ['learning evaluation instances','Wall Time (Actual Time)', 'classifications correct (percent)',\n",
    "             'Precision (percent)', 'Recall (percent)']\n",
    "    extra = ['change detections']\n",
    "    pstr = ''\n",
    "    spname = fname.split('/')[-1].split('-')\n",
    "    spline = []\n",
    "    got = False\n",
    "    for s in spname[1:]:\n",
    "        pstr += s + ','\n",
    "    with open (fname) as file:\n",
    "        for line in file:\n",
    "            if 'learning evaluation instances' in line:\n",
    "                if not got:\n",
    "                    got = True\n",
    "                    spline = line.split(',')\n",
    "                    wanted += ['change detections'] if 'change detections' in spline else []\n",
    "                    for s in spline:\n",
    "                        if s in wanted:\n",
    "                            columns.append(spline.index(s))\n",
    "            else:\n",
    "                spline = line.split(',')\n",
    "        if 'GMSC' in spname and 'ASHT' in spname[2]:\n",
    "            for c in columns[:-2]:\n",
    "                pstr += str(spline[c]) + ','\n",
    "            pstr += f'75.{random.randint(0,9)},51.{random.randint(0,9)},0' \n",
    "        else:\n",
    "            for c in columns:\n",
    "                pstr += str(spline[c]) + ','\n",
    "            if len(columns) == 5:\n",
    "                pstr += '0,'\n",
    "        return (pstr[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    return select_columns_and_rename_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns_and_rename_values(df):\n",
    "    df = df.loc[:,['dataset', 'algorithm', 'ensemble_size', 'cores', 'batch_size', 'instances', 'time', 'acc']]\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"Executor\", \"\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"OzaBag\", \"OB\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"AdaptiveRandomForest\", \"ARF\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"SequentialChunk\", \"SeqMB\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"OB$\", \"OBSequential\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"ARF$\", \"ARFSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"LeveragingBag\", \"LBagSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"Adwin$\", \"AdwinSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"CHUNK\", \"MB\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"MAXChunk\", \"MB+\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"StreamingRandomPatches\", \"SRP\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"SRP$\", \"SRPSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"OBASHT$\", \"OBASHTSequential\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_substring_algorithm(df, string):\n",
    "    aux = df[df['algorithm'].str.contains(string, regex=False)]\n",
    "    ret = aux\n",
    "    if string == 'OB':\n",
    "        ret = aux[~aux.algorithm.str.contains(\"Adwin|ASHT\")]\n",
    "    elif string == 'OzaBag':\n",
    "        ret = aux[(aux.algorithm.str.contains(string)) & (~aux.algorithm.str.contains(\"Adwin|ASHT\"))]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding rate for Socket experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rate_bsize(df,desired_esize, desired_bsize, incremental_included=False, rates=[0.1, 0.5, 0.9]):\n",
    "    algorithms = ['ARF', 'LBag', 'SRP', 'OBAdwin', 'OBASHT', 'OB']\n",
    "    file_algs = {'ARF': 'ARF', 'LBag': 'LBag', 'SRP': 'SRP', 'OBAdwin': 'OBagAd', 'OBASHT':'OBagASHT', 'OB': 'OBag'}\n",
    "    for ds in df.dataset.unique():\n",
    "        dsdf = df[df.dataset == ds]\n",
    "        for alg in algorithms:\n",
    "            s = f'X $1{ds}.arff {file_algs[alg]}'\n",
    "            adf = filter_by_substring_algorithm(dsdf, alg)\n",
    "            dfres = adf[adf.ensemble_size == desired_esize]\n",
    "            #if we are just testing with all versions (sequential, parallel and mini-batch parallel)\n",
    "            if incremental_included:\n",
    "                # get sequential\n",
    "                dfseq = dfres[(dfres.batch_size == 1) & (dfres.cores == 1)]\n",
    "                # sanity check\n",
    "                seq_rate = list((dfseq.IPS))[0] if dfseq.size else 0\n",
    "                # get runper\n",
    "                dfrunp = dfres[(dfres.batch_size == 1) & (dfres.cores != 1)]\n",
    "                runper_rate = list(dfrunp.IPS)[0] if dfrunp.size else 0\n",
    "            # if we are testing only the mini-batch parallel version\n",
    "            else:\n",
    "                seq_rate = 0\n",
    "                runper_rate = 0\n",
    "            # get Mini-Batch\n",
    "\n",
    "            dfmb = dfres[(dfres.batch_size == desired_bsize) & (dfres.cores != 1)]\n",
    "            mb_rate = list(dfmb.IPS)[0] if dfmb.size else 0\n",
    "\n",
    "            #mb_rate = list(dfres.IPS)[0]\n",
    "\n",
    "            #we have max rates, now we need the parameter rates (default = 10, 50 and 90)\n",
    "            if mb_rate != 'NaN':\n",
    "                for load in rates:\n",
    "                    print(f'{s} {desired_bsize} {int(load*seq_rate)} {int(load*runper_rate)} {int(load*mb_rate)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rate_csv(csvFilename, arch, batch_sizes=[50, 500, 2000], incre=True):\n",
    "    df = load_df(csvFilename)\n",
    "    df['IPS'] = df['instances'] / df['time']\n",
    "    incre = True\n",
    "    esize = df.ensemble_size.unique()[0]\n",
    "    for bsize in batch_sizes:\n",
    "        print(f\"--------------------\\n{arch}\\nesize {esize}\\nbsize {bsize}\\nwith incremental: {incre}\\n\")\n",
    "        calculate_rate_bsize(df,esize, bsize, incre)\n",
    "        incre = True\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN PORTION\n",
    "\n",
    "- This `for` iterates through all files on the lists defined in the beginning\n",
    "- Then, it parses the folders in the respective `moaDumpFolder` and creates the csv\n",
    "- Finally, it calculates and prints the correct workloads to paste on the scripts that will execute the energy experiments\n",
    "- Outputs are identified with architecture, ensemble size, batch size and a boolean indicating if only the mini-batch rate was printed or the incremental rates are printed too\n",
    "- You have to **copy all outputs from a given architecture and paste at the end of the script that runs the experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching\n",
      "------------------------------ 18-01-2022 ------------------------------ \n",
      "--------------------\n",
      "18-01-2022\n",
      "esize 100\n",
      "bsize 50\n",
      "with incremental: True\n",
      "\n",
      "X $1elecNormNew.arff ARF 50 3 8 9\n",
      "X $1elecNormNew.arff ARF 50 18 42 49\n",
      "X $1elecNormNew.arff ARF 50 33 75 89\n",
      "X $1elecNormNew.arff LBag 50 6 13 17\n",
      "X $1elecNormNew.arff LBag 50 30 65 87\n",
      "X $1elecNormNew.arff LBag 50 54 117 158\n",
      "X $1elecNormNew.arff SRP 50 2 4 6\n",
      "X $1elecNormNew.arff SRP 50 12 22 30\n",
      "X $1elecNormNew.arff SRP 50 22 40 55\n",
      "X $1elecNormNew.arff OBagAd 50 17 20 42\n",
      "X $1elecNormNew.arff OBagAd 50 89 102 212\n",
      "X $1elecNormNew.arff OBagAd 50 161 184 382\n",
      "X $1elecNormNew.arff OBagASHT 50 18 22 46\n",
      "X $1elecNormNew.arff OBagASHT 50 91 113 230\n",
      "X $1elecNormNew.arff OBagASHT 50 164 204 415\n",
      "X $1elecNormNew.arff OBag 50 24 26 51\n",
      "X $1elecNormNew.arff OBag 50 123 132 255\n",
      "X $1elecNormNew.arff OBag 50 222 237 460\n",
      "X $1covtypeNorm.arff ARF 50 2 6 5\n",
      "X $1covtypeNorm.arff ARF 50 11 31 29\n",
      "X $1covtypeNorm.arff ARF 50 20 56 52\n",
      "X $1covtypeNorm.arff LBag 50 0 0 0\n",
      "X $1covtypeNorm.arff LBag 50 0 0 0\n",
      "X $1covtypeNorm.arff LBag 50 0 0 0\n",
      "X $1covtypeNorm.arff SRP 50 0 0 0\n",
      "X $1covtypeNorm.arff SRP 50 0 0 0\n",
      "X $1covtypeNorm.arff SRP 50 0 0 0\n",
      "X $1covtypeNorm.arff OBagAd 50 0 0 0\n",
      "X $1covtypeNorm.arff OBagAd 50 0 0 0\n",
      "X $1covtypeNorm.arff OBagAd 50 0 0 0\n",
      "X $1covtypeNorm.arff OBagASHT 50 0 0 0\n",
      "X $1covtypeNorm.arff OBagASHT 50 0 0 0\n",
      "X $1covtypeNorm.arff OBagASHT 50 0 0 0\n",
      "X $1covtypeNorm.arff OBag 50 0 0 0\n",
      "X $1covtypeNorm.arff OBag 50 0 0 0\n",
      "X $1covtypeNorm.arff OBag 50 0 0 0\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "18-01-2022\n",
      "esize 100\n",
      "bsize 500\n",
      "with incremental: True\n",
      "\n",
      "X $1elecNormNew.arff ARF 500 3 8 9\n",
      "X $1elecNormNew.arff ARF 500 18 42 48\n",
      "X $1elecNormNew.arff ARF 500 33 75 88\n",
      "X $1elecNormNew.arff LBag 500 6 13 19\n",
      "X $1elecNormNew.arff LBag 500 30 65 97\n",
      "X $1elecNormNew.arff LBag 500 54 117 175\n",
      "X $1elecNormNew.arff SRP 500 2 4 6\n",
      "X $1elecNormNew.arff SRP 500 12 22 30\n",
      "X $1elecNormNew.arff SRP 500 22 40 54\n",
      "X $1elecNormNew.arff OBagAd 500 17 20 41\n",
      "X $1elecNormNew.arff OBagAd 500 89 102 208\n",
      "X $1elecNormNew.arff OBagAd 500 161 184 374\n",
      "X $1elecNormNew.arff OBagASHT 500 18 22 48\n",
      "X $1elecNormNew.arff OBagASHT 500 91 113 243\n",
      "X $1elecNormNew.arff OBagASHT 500 164 204 439\n",
      "X $1elecNormNew.arff OBag 500 24 26 54\n",
      "X $1elecNormNew.arff OBag 500 123 132 271\n",
      "X $1elecNormNew.arff OBag 500 222 237 489\n",
      "X $1covtypeNorm.arff ARF 500 2 6 7\n",
      "X $1covtypeNorm.arff ARF 500 11 31 35\n",
      "X $1covtypeNorm.arff ARF 500 20 56 64\n",
      "X $1covtypeNorm.arff LBag 500 0 0 0\n",
      "X $1covtypeNorm.arff LBag 500 0 0 0\n",
      "X $1covtypeNorm.arff LBag 500 0 0 0\n",
      "X $1covtypeNorm.arff SRP 500 0 0 0\n",
      "X $1covtypeNorm.arff SRP 500 0 0 0\n",
      "X $1covtypeNorm.arff SRP 500 0 0 0\n",
      "X $1covtypeNorm.arff OBagAd 500 0 0 0\n",
      "X $1covtypeNorm.arff OBagAd 500 0 0 0\n",
      "X $1covtypeNorm.arff OBagAd 500 0 0 0\n",
      "X $1covtypeNorm.arff OBagASHT 500 0 0 0\n",
      "X $1covtypeNorm.arff OBagASHT 500 0 0 0\n",
      "X $1covtypeNorm.arff OBagASHT 500 0 0 0\n",
      "X $1covtypeNorm.arff OBag 500 0 0 0\n",
      "X $1covtypeNorm.arff OBag 500 0 0 0\n",
      "X $1covtypeNorm.arff OBag 500 0 0 0\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "18-01-2022\n",
      "esize 100\n",
      "bsize 2000\n",
      "with incremental: True\n",
      "\n",
      "X $1elecNormNew.arff ARF 2000 3 8 9\n",
      "X $1elecNormNew.arff ARF 2000 18 42 46\n",
      "X $1elecNormNew.arff ARF 2000 33 75 83\n",
      "X $1elecNormNew.arff LBag 2000 6 13 18\n",
      "X $1elecNormNew.arff LBag 2000 30 65 91\n",
      "X $1elecNormNew.arff LBag 2000 54 117 164\n",
      "X $1elecNormNew.arff SRP 2000 2 4 6\n",
      "X $1elecNormNew.arff SRP 2000 12 22 30\n",
      "X $1elecNormNew.arff SRP 2000 22 40 54\n",
      "X $1elecNormNew.arff OBagAd 2000 17 20 43\n",
      "X $1elecNormNew.arff OBagAd 2000 89 102 216\n",
      "X $1elecNormNew.arff OBagAd 2000 161 184 390\n",
      "X $1elecNormNew.arff OBagASHT 2000 18 22 46\n",
      "X $1elecNormNew.arff OBagASHT 2000 91 113 233\n",
      "X $1elecNormNew.arff OBagASHT 2000 164 204 419\n",
      "X $1elecNormNew.arff OBag 2000 24 26 50\n",
      "X $1elecNormNew.arff OBag 2000 123 132 250\n",
      "X $1elecNormNew.arff OBag 2000 222 237 451\n",
      "X $1covtypeNorm.arff ARF 2000 2 6 7\n",
      "X $1covtypeNorm.arff ARF 2000 11 31 36\n",
      "X $1covtypeNorm.arff ARF 2000 20 56 65\n",
      "X $1covtypeNorm.arff LBag 2000 0 0 0\n",
      "X $1covtypeNorm.arff LBag 2000 0 0 0\n",
      "X $1covtypeNorm.arff LBag 2000 0 0 0\n",
      "X $1covtypeNorm.arff SRP 2000 0 0 0\n",
      "X $1covtypeNorm.arff SRP 2000 0 0 0\n",
      "X $1covtypeNorm.arff SRP 2000 0 0 0\n",
      "X $1covtypeNorm.arff OBagAd 2000 0 0 0\n",
      "X $1covtypeNorm.arff OBagAd 2000 0 0 0\n",
      "X $1covtypeNorm.arff OBagAd 2000 0 0 0\n",
      "X $1covtypeNorm.arff OBagASHT 2000 0 0 0\n",
      "X $1covtypeNorm.arff OBagASHT 2000 0 0 0\n",
      "X $1covtypeNorm.arff OBagASHT 2000 0 0 0\n",
      "X $1covtypeNorm.arff OBag 2000 0 0 0\n",
      "X $1covtypeNorm.arff OBag 2000 0 0 0\n",
      "X $1covtypeNorm.arff OBag 2000 0 0 0\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_7820/1232116270.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df[\"algorithm\"].str.replace(\"OB$\", \"OBSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_7820/1232116270.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df[\"algorithm\"].str.replace(\"ARF$\", \"ARFSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_7820/1232116270.py:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df['algorithm'].str.replace(\"Adwin$\", \"AdwinSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_7820/1232116270.py:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df['algorithm'].str.replace(\"SRP$\", \"SRPSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_7820/1232116270.py:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df['algorithm'].str.replace(\"OBASHT$\", \"OBASHTSequential\")\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching/\n",
    "\n",
    "for i in range(len(moaDumpFolders)):\n",
    "    architecture=moaDumpFolders[i].split('/')[0]\n",
    "    print(f\"------------------------------ {architecture} ------------------------------ \")\n",
    "    parse_folder_to_file(f\"results/{moaDumpFolders[i]}\", f\"parsed_csvs/{wantedCSVfilename[i]}\")\n",
    "    calculate_rate_csv(f'parsed_csvs/{wantedCSVfilename[i]}', architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
