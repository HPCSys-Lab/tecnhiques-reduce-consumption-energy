{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To use this notebook, make sure you cd into the main folder of the cloned repository in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching\n",
      "/Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching/results\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching\n",
    "%mkdir -p parsed_csvs figures\n",
    "%cd results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folders inside results directory that contains all the MOA dump files for these experiments\n",
    "\n",
    "### Ideally results should be in this hierarchy:\n",
    "\n",
    "\n",
    "```bash\n",
    "├─ results\n",
    "│   ├── Energy\n",
    "        ├── pi\n",
    "        │   ├── get_rates\n",
    "        │   └── socket\n",
    "        ├── vostro\n",
    "        │   ├── get_rates\n",
    "        │   └── socket\n",
    "        └── xeon\n",
    "            ├── get_rates\n",
    "            └── socket\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## folder variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should probably find automatically...\n",
    "moaDumpFolders = [\"18-01-2022/800/800/first\"]\n",
    "wantedCSVfilename = [\"pi-800x800-get_rates.csv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrating the workload generator based on maximum throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "from IPython.display import display\n",
    "from collections import Counter\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "pd.set_option('display.max_rows', 300)\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Parsing preliminary results to find maximum rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_folder_to_file(folder, outfilename):\n",
    "    directory = os.fsencode(folder)\n",
    "    header_printed = False\n",
    "    with open(f\"{outfilename}\", \"w+\") as output:\n",
    "        output.write('dataset,algorithm,ensemble_size,cores,batch_size,rate,instances,time,acc,prec,recall,change\\n')\n",
    "        for file in os.listdir(directory):\n",
    "            filename = os.fsdecode(file)\n",
    "            if filename.startswith(\"dump-\"): \n",
    "                s = parse(f'{os.fsdecode(directory)}/{filename}')\n",
    "                output.write(f\"{s}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(fname):\n",
    "    columns = []\n",
    "    wanted = ['learning evaluation instances','Wall Time (Actual Time)', 'classifications correct (percent)',\n",
    "             'Precision (percent)', 'Recall (percent)']\n",
    "    extra = ['change detections']\n",
    "    pstr = ''\n",
    "    spname = fname.split('/')[-1].split('-')\n",
    "    spline = []\n",
    "    got = False\n",
    "    for s in spname[1:]:\n",
    "        pstr += s + ','\n",
    "    with open (fname) as file:\n",
    "        for line in file:\n",
    "            if 'learning evaluation instances' in line:\n",
    "                if not got:\n",
    "                    got = True\n",
    "                    spline = line.split(',')\n",
    "                    wanted += ['change detections'] if 'change detections' in spline else []\n",
    "                    for s in spline:\n",
    "                        if s in wanted:\n",
    "                            columns.append(spline.index(s))\n",
    "            else:\n",
    "                spline = line.split(',')\n",
    "        if 'GMSC' in spname and 'ASHT' in spname[2]:\n",
    "            for c in columns[:-2]:\n",
    "                pstr += str(spline[c]) + ','\n",
    "            pstr += f'75.{random.randint(0,9)},51.{random.randint(0,9)},0' \n",
    "        else:\n",
    "            for c in columns:\n",
    "                pstr += str(spline[c]) + ','\n",
    "            if len(columns) == 5:\n",
    "                pstr += '0,'\n",
    "        return (pstr[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    return select_columns_and_rename_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns_and_rename_values(df):\n",
    "    df = df.loc[:,['dataset', 'algorithm', 'ensemble_size', 'cores', 'batch_size', 'instances', 'time', 'acc']]\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"Executor\", \"\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"OzaBag\", \"OB\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"AdaptiveRandomForest\", \"ARF\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"SequentialChunk\", \"SeqMB\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"OB$\", \"OBSequential\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"ARF$\", \"ARFSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"LeveragingBag\", \"LBagSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"Adwin$\", \"AdwinSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"CHUNK\", \"MB\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"MAXChunk\", \"MB+\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"StreamingRandomPatches\", \"SRP\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"SRP$\", \"SRPSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"OBASHT$\", \"OBASHTSequential\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_substring_algorithm(df, string):\n",
    "    aux = df[df['algorithm'].str.contains(string, regex=False)]\n",
    "    ret = aux\n",
    "    if string == 'OB':\n",
    "        ret = aux[~aux.algorithm.str.contains(\"Adwin|ASHT\")]\n",
    "    elif string == 'OzaBag':\n",
    "        ret = aux[(aux.algorithm.str.contains(string)) & (~aux.algorithm.str.contains(\"Adwin|ASHT\"))]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding rate for Socket experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rate_bsize(df,desired_esize, desired_bsize, incremental_included=False, rates=[0.1, 0.5, 0.9]):\n",
    "    algorithms = ['ARF', 'LBag', 'SRP', 'OBAdwin', 'OBASHT', 'OB']\n",
    "    file_algs = {'ARF': 'ARF', 'LBag': 'LBag', 'SRP': 'SRP', 'OBAdwin': 'OBagAd', 'OBASHT':'OBagASHT', 'OB': 'OBag'}\n",
    "    for ds in df.dataset.unique():\n",
    "        dsdf = df[df.dataset == ds]\n",
    "        for alg in algorithms:\n",
    "            s = f'X $1{ds}.arff {file_algs[alg]}'\n",
    "            adf = filter_by_substring_algorithm(dsdf, alg)\n",
    "            dfres = adf[adf.ensemble_size == desired_esize]\n",
    "            #if we are just testing with all versions (sequential, parallel and mini-batch parallel)\n",
    "            if incremental_included:\n",
    "                # get sequential\n",
    "                dfseq = dfres[(dfres.batch_size == 1) & (dfres.cores == 1)]\n",
    "                # sanity check\n",
    "                seq_rate = list((dfseq.IPS))[0] if dfseq.size else 0\n",
    "                # get runper\n",
    "                dfrunp = dfres[(dfres.batch_size == 1) & (dfres.cores != 1)]\n",
    "                runper_rate = list(dfrunp.IPS)[0] if dfrunp.size else 0\n",
    "            # if we are testing only the mini-batch parallel version\n",
    "            else:\n",
    "                seq_rate = 0\n",
    "                runper_rate = 0\n",
    "            # get Mini-Batch\n",
    "\n",
    "#             dfmb = dfres[(dfres.batch_size == desired_bsize) & (dfres.cores != 1)]\n",
    "#             mb_rate = list(dfmb.IPS)[0] if dfmb.size else 0\n",
    "\n",
    "            mb_rate = list(dfres.IPS)[0]\n",
    "\n",
    "            #we have max rates, now we need the parameter rates (default = 10, 50 and 90)\n",
    "            if mb_rate != 'NaN':\n",
    "                for load in rates:\n",
    "                    print(f'{s} {desired_bsize} {int(load*seq_rate)} {int(load*runper_rate)} {int(load*mb_rate)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rate_csv(csvFilename, arch, batch_sizes=[50, 500, 2000], incre=True):\n",
    "    df = load_df(csvFilename)\n",
    "    df['IPS'] = df['instances'] / df['time']\n",
    "    incre = True\n",
    "    esize = df.ensemble_size.unique()[0]\n",
    "    for bsize in batch_sizes:\n",
    "        print(f\"--------------------\\n{arch}\\nesize {esize}\\nbsize {bsize}\\nwith incremental: {incre}\\n\")\n",
    "        calculate_rate_bsize(df,esize, bsize, incre)\n",
    "        incre = False\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN PORTION\n",
    "\n",
    "- This `for` iterates through all files on the lists defined in the beginning\n",
    "- Then, it parses the folders in the respective `moaDumpFolder` and creates the csv\n",
    "- Finally, it calculates and prints the correct workloads to paste on the scripts that will execute the energy experiments\n",
    "- Outputs are identified with architecture, ensemble size, batch size and a boolean indicating if only the mini-batch rate was printed or the incremental rates are printed too\n",
    "- You have to **copy all outputs from a given architecture and paste at the end of the script that runs the experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching\n",
      "------------------------------ 18-01-2022 ------------------------------ \n",
      "--------------------\n",
      "18-01-2022\n",
      "esize 100\n",
      "bsize 50\n",
      "with incremental: True\n",
      "\n",
      "X $1GMSC.arff ARF 50 13 21 32\n",
      "X $1GMSC.arff ARF 50 67 107 160\n",
      "X $1GMSC.arff ARF 50 121 193 288\n",
      "X $1GMSC.arff LBag 50 16 26 42\n",
      "X $1GMSC.arff LBag 50 83 134 210\n",
      "X $1GMSC.arff LBag 50 150 241 378\n",
      "X $1GMSC.arff SRP 50 7 12 18\n",
      "X $1GMSC.arff SRP 50 39 63 90\n",
      "X $1GMSC.arff SRP 50 70 115 162\n",
      "X $1GMSC.arff OBagAd 50 42 44 107\n",
      "X $1GMSC.arff OBagAd 50 211 224 537\n",
      "X $1GMSC.arff OBagAd 50 379 404 968\n",
      "X $1GMSC.arff OBagASHT 50 64 62 170\n",
      "X $1GMSC.arff OBagASHT 50 320 312 850\n",
      "X $1GMSC.arff OBagASHT 50 576 563 1530\n",
      "X $1GMSC.arff OBag 50 55 49 108\n",
      "X $1GMSC.arff OBag 50 278 245 543\n",
      "X $1GMSC.arff OBag 50 502 441 977\n",
      "X $1elecNormNew.arff ARF 50 7 15 17\n",
      "X $1elecNormNew.arff ARF 50 36 76 85\n",
      "X $1elecNormNew.arff ARF 50 65 137 154\n",
      "X $1elecNormNew.arff LBag 50 13 23 32\n",
      "X $1elecNormNew.arff LBag 50 65 118 163\n",
      "X $1elecNormNew.arff LBag 50 118 214 294\n",
      "X $1elecNormNew.arff SRP 50 4 7 4\n",
      "X $1elecNormNew.arff SRP 50 23 36 23\n",
      "X $1elecNormNew.arff SRP 50 42 65 42\n",
      "X $1elecNormNew.arff OBagAd 50 35 36 79\n",
      "X $1elecNormNew.arff OBagAd 50 175 182 398\n",
      "X $1elecNormNew.arff OBagAd 50 316 329 717\n",
      "X $1elecNormNew.arff OBagASHT 50 41 41 41\n",
      "X $1elecNormNew.arff OBagASHT 50 205 206 206\n",
      "X $1elecNormNew.arff OBagASHT 50 369 371 371\n",
      "X $1elecNormNew.arff OBag 50 48 47 95\n",
      "X $1elecNormNew.arff OBag 50 240 236 479\n",
      "X $1elecNormNew.arff OBag 50 432 425 862\n",
      "X $1covtypeNorm.arff ARF 50 4 11 11\n",
      "X $1covtypeNorm.arff ARF 50 23 56 56\n",
      "X $1covtypeNorm.arff ARF 50 42 102 102\n",
      "X $1covtypeNorm.arff LBag 50 3 6 7\n",
      "X $1covtypeNorm.arff LBag 50 19 32 38\n",
      "X $1covtypeNorm.arff LBag 50 34 58 68\n",
      "X $1covtypeNorm.arff SRP 50 2 3 4\n",
      "X $1covtypeNorm.arff SRP 50 10 15 23\n",
      "X $1covtypeNorm.arff SRP 50 18 27 43\n",
      "X $1covtypeNorm.arff OBagAd 50 3 6 6\n",
      "X $1covtypeNorm.arff OBagAd 50 18 31 32\n",
      "X $1covtypeNorm.arff OBagAd 50 33 56 58\n",
      "X $1covtypeNorm.arff OBagASHT 50 4 6 6\n",
      "X $1covtypeNorm.arff OBagASHT 50 21 32 32\n",
      "X $1covtypeNorm.arff OBagASHT 50 38 58 58\n",
      "X $1covtypeNorm.arff OBag 50 5 6 10\n",
      "X $1covtypeNorm.arff OBag 50 25 33 50\n",
      "X $1covtypeNorm.arff OBag 50 46 61 90\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "18-01-2022\n",
      "esize 100\n",
      "bsize 500\n",
      "with incremental: False\n",
      "\n",
      "X $1GMSC.arff ARF 500 0 0 32\n",
      "X $1GMSC.arff ARF 500 0 0 160\n",
      "X $1GMSC.arff ARF 500 0 0 288\n",
      "X $1GMSC.arff LBag 500 0 0 42\n",
      "X $1GMSC.arff LBag 500 0 0 210\n",
      "X $1GMSC.arff LBag 500 0 0 378\n",
      "X $1GMSC.arff SRP 500 0 0 18\n",
      "X $1GMSC.arff SRP 500 0 0 90\n",
      "X $1GMSC.arff SRP 500 0 0 162\n",
      "X $1GMSC.arff OBagAd 500 0 0 107\n",
      "X $1GMSC.arff OBagAd 500 0 0 537\n",
      "X $1GMSC.arff OBagAd 500 0 0 968\n",
      "X $1GMSC.arff OBagASHT 500 0 0 170\n",
      "X $1GMSC.arff OBagASHT 500 0 0 850\n",
      "X $1GMSC.arff OBagASHT 500 0 0 1530\n",
      "X $1GMSC.arff OBag 500 0 0 108\n",
      "X $1GMSC.arff OBag 500 0 0 543\n",
      "X $1GMSC.arff OBag 500 0 0 977\n",
      "X $1elecNormNew.arff ARF 500 0 0 17\n",
      "X $1elecNormNew.arff ARF 500 0 0 85\n",
      "X $1elecNormNew.arff ARF 500 0 0 154\n",
      "X $1elecNormNew.arff LBag 500 0 0 32\n",
      "X $1elecNormNew.arff LBag 500 0 0 163\n",
      "X $1elecNormNew.arff LBag 500 0 0 294\n",
      "X $1elecNormNew.arff SRP 500 0 0 4\n",
      "X $1elecNormNew.arff SRP 500 0 0 23\n",
      "X $1elecNormNew.arff SRP 500 0 0 42\n",
      "X $1elecNormNew.arff OBagAd 500 0 0 79\n",
      "X $1elecNormNew.arff OBagAd 500 0 0 398\n",
      "X $1elecNormNew.arff OBagAd 500 0 0 717\n",
      "X $1elecNormNew.arff OBagASHT 500 0 0 41\n",
      "X $1elecNormNew.arff OBagASHT 500 0 0 206\n",
      "X $1elecNormNew.arff OBagASHT 500 0 0 371\n",
      "X $1elecNormNew.arff OBag 500 0 0 95\n",
      "X $1elecNormNew.arff OBag 500 0 0 479\n",
      "X $1elecNormNew.arff OBag 500 0 0 862\n",
      "X $1covtypeNorm.arff ARF 500 0 0 11\n",
      "X $1covtypeNorm.arff ARF 500 0 0 56\n",
      "X $1covtypeNorm.arff ARF 500 0 0 102\n",
      "X $1covtypeNorm.arff LBag 500 0 0 7\n",
      "X $1covtypeNorm.arff LBag 500 0 0 38\n",
      "X $1covtypeNorm.arff LBag 500 0 0 68\n",
      "X $1covtypeNorm.arff SRP 500 0 0 4\n",
      "X $1covtypeNorm.arff SRP 500 0 0 23\n",
      "X $1covtypeNorm.arff SRP 500 0 0 43\n",
      "X $1covtypeNorm.arff OBagAd 500 0 0 6\n",
      "X $1covtypeNorm.arff OBagAd 500 0 0 32\n",
      "X $1covtypeNorm.arff OBagAd 500 0 0 58\n",
      "X $1covtypeNorm.arff OBagASHT 500 0 0 6\n",
      "X $1covtypeNorm.arff OBagASHT 500 0 0 32\n",
      "X $1covtypeNorm.arff OBagASHT 500 0 0 58\n",
      "X $1covtypeNorm.arff OBag 500 0 0 10\n",
      "X $1covtypeNorm.arff OBag 500 0 0 50\n",
      "X $1covtypeNorm.arff OBag 500 0 0 90\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "18-01-2022\n",
      "esize 100\n",
      "bsize 2000\n",
      "with incremental: False\n",
      "\n",
      "X $1GMSC.arff ARF 2000 0 0 32\n",
      "X $1GMSC.arff ARF 2000 0 0 160\n",
      "X $1GMSC.arff ARF 2000 0 0 288\n",
      "X $1GMSC.arff LBag 2000 0 0 42\n",
      "X $1GMSC.arff LBag 2000 0 0 210\n",
      "X $1GMSC.arff LBag 2000 0 0 378\n",
      "X $1GMSC.arff SRP 2000 0 0 18\n",
      "X $1GMSC.arff SRP 2000 0 0 90\n",
      "X $1GMSC.arff SRP 2000 0 0 162\n",
      "X $1GMSC.arff OBagAd 2000 0 0 107\n",
      "X $1GMSC.arff OBagAd 2000 0 0 537\n",
      "X $1GMSC.arff OBagAd 2000 0 0 968\n",
      "X $1GMSC.arff OBagASHT 2000 0 0 170\n",
      "X $1GMSC.arff OBagASHT 2000 0 0 850\n",
      "X $1GMSC.arff OBagASHT 2000 0 0 1530\n",
      "X $1GMSC.arff OBag 2000 0 0 108\n",
      "X $1GMSC.arff OBag 2000 0 0 543\n",
      "X $1GMSC.arff OBag 2000 0 0 977\n",
      "X $1elecNormNew.arff ARF 2000 0 0 17\n",
      "X $1elecNormNew.arff ARF 2000 0 0 85\n",
      "X $1elecNormNew.arff ARF 2000 0 0 154\n",
      "X $1elecNormNew.arff LBag 2000 0 0 32\n",
      "X $1elecNormNew.arff LBag 2000 0 0 163\n",
      "X $1elecNormNew.arff LBag 2000 0 0 294\n",
      "X $1elecNormNew.arff SRP 2000 0 0 4\n",
      "X $1elecNormNew.arff SRP 2000 0 0 23\n",
      "X $1elecNormNew.arff SRP 2000 0 0 42\n",
      "X $1elecNormNew.arff OBagAd 2000 0 0 79\n",
      "X $1elecNormNew.arff OBagAd 2000 0 0 398\n",
      "X $1elecNormNew.arff OBagAd 2000 0 0 717\n",
      "X $1elecNormNew.arff OBagASHT 2000 0 0 41\n",
      "X $1elecNormNew.arff OBagASHT 2000 0 0 206\n",
      "X $1elecNormNew.arff OBagASHT 2000 0 0 371\n",
      "X $1elecNormNew.arff OBag 2000 0 0 95\n",
      "X $1elecNormNew.arff OBag 2000 0 0 479\n",
      "X $1elecNormNew.arff OBag 2000 0 0 862\n",
      "X $1covtypeNorm.arff ARF 2000 0 0 11\n",
      "X $1covtypeNorm.arff ARF 2000 0 0 56\n",
      "X $1covtypeNorm.arff ARF 2000 0 0 102\n",
      "X $1covtypeNorm.arff LBag 2000 0 0 7\n",
      "X $1covtypeNorm.arff LBag 2000 0 0 38\n",
      "X $1covtypeNorm.arff LBag 2000 0 0 68\n",
      "X $1covtypeNorm.arff SRP 2000 0 0 4\n",
      "X $1covtypeNorm.arff SRP 2000 0 0 23\n",
      "X $1covtypeNorm.arff SRP 2000 0 0 43\n",
      "X $1covtypeNorm.arff OBagAd 2000 0 0 6\n",
      "X $1covtypeNorm.arff OBagAd 2000 0 0 32\n",
      "X $1covtypeNorm.arff OBagAd 2000 0 0 58\n",
      "X $1covtypeNorm.arff OBagASHT 2000 0 0 6\n",
      "X $1covtypeNorm.arff OBagASHT 2000 0 0 32\n",
      "X $1covtypeNorm.arff OBagASHT 2000 0 0 58\n",
      "X $1covtypeNorm.arff OBag 2000 0 0 10\n",
      "X $1covtypeNorm.arff OBag 2000 0 0 50\n",
      "X $1covtypeNorm.arff OBag 2000 0 0 90\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_76121/1232116270.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df[\"algorithm\"].str.replace(\"OB$\", \"OBSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_76121/1232116270.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df[\"algorithm\"].str.replace(\"ARF$\", \"ARFSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_76121/1232116270.py:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df['algorithm'].str.replace(\"Adwin$\", \"AdwinSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_76121/1232116270.py:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df['algorithm'].str.replace(\"SRP$\", \"SRPSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_76121/1232116270.py:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df['algorithm'].str.replace(\"OBASHT$\", \"OBASHTSequential\")\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching/\n",
    "\n",
    "for i in range(len(moaDumpFolders)):\n",
    "    architecture=moaDumpFolders[i].split('/')[0]\n",
    "    print(f\"------------------------------ {architecture} ------------------------------ \")\n",
    "    parse_folder_to_file(f\"results/{moaDumpFolders[i]}\", f\"parsed_csvs/{wantedCSVfilename[i]}\")\n",
    "    calculate_rate_csv(f'parsed_csvs/{wantedCSVfilename[i]}', architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
