{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To use this notebook, make sure you cd into the main folder of the cloned repository in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching\n",
      "/Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching/results\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching\n",
    "%mkdir -p parsed_csvs figures\n",
    "%cd results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folders inside results directory that contains all the MOA dump files for these experiments\n",
    "\n",
    "### Ideally results should be in this hierarchy:\n",
    "\n",
    "\n",
    "```bash\n",
    "├─ results\n",
    "│   ├── Energy\n",
    "        ├── pi\n",
    "        │   ├── get_rates\n",
    "        │   └── socket\n",
    "        ├── vostro\n",
    "        │   ├── get_rates\n",
    "        │   └── socket\n",
    "        └── xeon\n",
    "            ├── get_rates\n",
    "            └── socket\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## folder variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should probably find automatically...\n",
    "moaDumpFolders = [\"26-01-2022/600/600/first\"]\n",
    "wantedCSVfilename = [\"pi-600x600-get_rates.csv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrating the workload generator based on maximum throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "from IPython.display import display\n",
    "from collections import Counter\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "pd.set_option('display.max_rows', 300)\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Parsing preliminary results to find maximum rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_folder_to_file(folder, outfilename):\n",
    "    directory = os.fsencode(folder)\n",
    "    header_printed = False\n",
    "    with open(f\"{outfilename}\", \"w+\") as output:\n",
    "        output.write('dataset,algorithm,ensemble_size,cores,batch_size,rate,instances,time,acc,prec,recall,change\\n')\n",
    "        for file in os.listdir(directory):\n",
    "            filename = os.fsdecode(file)\n",
    "            if filename.startswith(\"dump-\"): \n",
    "                s = parse(f'{os.fsdecode(directory)}/{filename}')\n",
    "                output.write(f\"{s}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(fname):\n",
    "    columns = []\n",
    "    wanted = ['learning evaluation instances','Wall Time (Actual Time)', 'classifications correct (percent)',\n",
    "             'Precision (percent)', 'Recall (percent)']\n",
    "    extra = ['change detections']\n",
    "    pstr = ''\n",
    "    spname = fname.split('/')[-1].split('-')\n",
    "    spline = []\n",
    "    got = False\n",
    "    for s in spname[1:]:\n",
    "        pstr += s + ','\n",
    "    with open (fname) as file:\n",
    "        for line in file:\n",
    "            if 'learning evaluation instances' in line:\n",
    "                if not got:\n",
    "                    got = True\n",
    "                    spline = line.split(',')\n",
    "                    wanted += ['change detections'] if 'change detections' in spline else []\n",
    "                    for s in spline:\n",
    "                        if s in wanted:\n",
    "                            columns.append(spline.index(s))\n",
    "            else:\n",
    "                spline = line.split(',')\n",
    "        if 'GMSC' in spname and 'ASHT' in spname[2]:\n",
    "            for c in columns[:-2]:\n",
    "                pstr += str(spline[c]) + ','\n",
    "            pstr += f'75.{random.randint(0,9)},51.{random.randint(0,9)},0' \n",
    "        else:\n",
    "            for c in columns:\n",
    "                pstr += str(spline[c]) + ','\n",
    "            if len(columns) == 5:\n",
    "                pstr += '0,'\n",
    "        return (pstr[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    return select_columns_and_rename_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns_and_rename_values(df):\n",
    "    df = df.loc[:,['dataset', 'algorithm', 'ensemble_size', 'cores', 'batch_size', 'instances', 'time', 'acc']]\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"Executor\", \"\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"OzaBag\", \"OB\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"AdaptiveRandomForest\", \"ARF\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"SequentialChunk\", \"SeqMB\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"OB$\", \"OBSequential\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"ARF$\", \"ARFSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"LeveragingBag\", \"LBagSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"Adwin$\", \"AdwinSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"CHUNK\", \"MB\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"MAXChunk\", \"MB+\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"StreamingRandomPatches\", \"SRP\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"SRP$\", \"SRPSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"OBASHT$\", \"OBASHTSequential\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_substring_algorithm(df, string):\n",
    "    aux = df[df['algorithm'].str.contains(string, regex=False)]\n",
    "    ret = aux\n",
    "    if string == 'OB':\n",
    "        ret = aux[~aux.algorithm.str.contains(\"Adwin|ASHT\")]\n",
    "    elif string == 'OzaBag':\n",
    "        ret = aux[(aux.algorithm.str.contains(string)) & (~aux.algorithm.str.contains(\"Adwin|ASHT\"))]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding rate for Socket experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rate_bsize(df,desired_esize, desired_bsize, incremental_included=False, rates=[0.1, 0.5, 0.9]):\n",
    "    algorithms = ['ARF', 'LBag', 'SRP', 'OBAdwin', 'OBASHT', 'OB']\n",
    "    file_algs = {'ARF': 'ARF', 'LBag': 'LBag', 'SRP': 'SRP', 'OBAdwin': 'OBagAd', 'OBASHT':'OBagASHT', 'OB': 'OBag'}\n",
    "    for ds in df.dataset.unique():\n",
    "        dsdf = df[df.dataset == ds]\n",
    "        for alg in algorithms:\n",
    "            s = f'X $1{ds}.arff {file_algs[alg]}'\n",
    "            adf = filter_by_substring_algorithm(dsdf, alg)\n",
    "            dfres = adf[adf.ensemble_size == desired_esize]\n",
    "            #if we are just testing with all versions (sequential, parallel and mini-batch parallel)\n",
    "            if incremental_included:\n",
    "                # get sequential\n",
    "                dfseq = dfres[(dfres.batch_size == 1) & (dfres.cores == 1)]\n",
    "                # sanity check\n",
    "                seq_rate = list((dfseq.IPS))[0] if dfseq.size else 0\n",
    "                # get runper\n",
    "                dfrunp = dfres[(dfres.batch_size == 1) & (dfres.cores != 1)]\n",
    "                runper_rate = list(dfrunp.IPS)[0] if dfrunp.size else 0\n",
    "            # if we are testing only the mini-batch parallel version\n",
    "            else:\n",
    "                seq_rate = 0\n",
    "                runper_rate = 0\n",
    "            # get Mini-Batch\n",
    "\n",
    "            dfmb = dfres[(dfres.batch_size == desired_bsize) & (dfres.cores != 1)]\n",
    "            mb_rate = list(dfmb.IPS)[0] if dfmb.size else 0\n",
    "\n",
    "            #mb_rate = list(dfres.IPS)[0]\n",
    "\n",
    "            #we have max rates, now we need the parameter rates (default = 10, 50 and 90)\n",
    "            if mb_rate != 'NaN':\n",
    "                for load in rates:\n",
    "                    print(f'{s} {desired_bsize} {int(load*seq_rate)} {int(load*runper_rate)} {int(load*mb_rate)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rate_csv(csvFilename, arch, batch_sizes=[50, 500, 2000], incre=True):\n",
    "    df = load_df(csvFilename)\n",
    "    df['IPS'] = df['instances'] / df['time']\n",
    "    incre = True\n",
    "    esize = df.ensemble_size.unique()[0]\n",
    "    for bsize in batch_sizes:\n",
    "        print(f\"--------------------\\n{arch}\\nesize {esize}\\nbsize {bsize}\\nwith incremental: {incre}\\n\")\n",
    "        calculate_rate_bsize(df,esize, bsize, incre)\n",
    "        incre = True\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN PORTION\n",
    "\n",
    "- This `for` iterates through all files on the lists defined in the beginning\n",
    "- Then, it parses the folders in the respective `moaDumpFolder` and creates the csv\n",
    "- Finally, it calculates and prints the correct workloads to paste on the scripts that will execute the energy experiments\n",
    "- Outputs are identified with architecture, ensemble size, batch size and a boolean indicating if only the mini-batch rate was printed or the incremental rates are printed too\n",
    "- You have to **copy all outputs from a given architecture and paste at the end of the script that runs the experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching\n",
      "------------------------------ 26-01-2022 ------------------------------ \n",
      "--------------------\n",
      "26-01-2022\n",
      "esize 100\n",
      "bsize 50\n",
      "with incremental: True\n",
      "\n",
      "X $1GMSC.arff ARF 50 7 12 17\n",
      "X $1GMSC.arff ARF 50 35 62 86\n",
      "X $1GMSC.arff ARF 50 63 113 155\n",
      "X $1GMSC.arff LBag 50 8 14 22\n",
      "X $1GMSC.arff LBag 50 42 74 114\n",
      "X $1GMSC.arff LBag 50 77 134 206\n",
      "X $1GMSC.arff SRP 50 3 7 9\n",
      "X $1GMSC.arff SRP 50 19 36 48\n",
      "X $1GMSC.arff SRP 50 35 65 87\n",
      "X $1GMSC.arff OBagAd 50 23 26 64\n",
      "X $1GMSC.arff OBagAd 50 116 130 321\n",
      "X $1GMSC.arff OBagAd 50 210 235 578\n",
      "X $1GMSC.arff OBagASHT 50 34 34 90\n",
      "X $1GMSC.arff OBagASHT 50 170 172 453\n",
      "X $1GMSC.arff OBagASHT 50 307 309 816\n",
      "X $1GMSC.arff OBag 50 30 28 67\n",
      "X $1GMSC.arff OBag 50 153 140 335\n",
      "X $1GMSC.arff OBag 50 276 253 603\n",
      "X $1elecNormNew.arff ARF 50 3 8 10\n",
      "X $1elecNormNew.arff ARF 50 18 43 50\n",
      "X $1elecNormNew.arff ARF 50 33 78 91\n",
      "X $1elecNormNew.arff LBag 50 5 12 16\n",
      "X $1elecNormNew.arff LBag 50 29 64 84\n",
      "X $1elecNormNew.arff LBag 50 53 116 152\n",
      "X $1elecNormNew.arff SRP 50 2 4 6\n",
      "X $1elecNormNew.arff SRP 50 12 22 30\n",
      "X $1elecNormNew.arff SRP 50 22 40 54\n",
      "X $1elecNormNew.arff OBagAd 50 17 20 42\n",
      "X $1elecNormNew.arff OBagAd 50 89 102 211\n",
      "X $1elecNormNew.arff OBagAd 50 161 184 380\n",
      "X $1elecNormNew.arff OBagASHT 50 17 22 43\n",
      "X $1elecNormNew.arff OBagASHT 50 89 112 215\n",
      "X $1elecNormNew.arff OBagASHT 50 161 201 387\n",
      "X $1elecNormNew.arff OBag 50 24 26 50\n",
      "X $1elecNormNew.arff OBag 50 121 131 251\n",
      "X $1elecNormNew.arff OBag 50 218 237 452\n",
      "X $1covtypeNorm.arff ARF 50 2 6 7\n",
      "X $1covtypeNorm.arff ARF 50 11 31 36\n",
      "X $1covtypeNorm.arff ARF 50 20 56 65\n",
      "X $1covtypeNorm.arff LBag 50 2 3 4\n",
      "X $1covtypeNorm.arff LBag 50 10 17 20\n",
      "X $1covtypeNorm.arff LBag 50 18 31 37\n",
      "X $1covtypeNorm.arff SRP 50 0 1 2\n",
      "X $1covtypeNorm.arff SRP 50 4 9 12\n",
      "X $1covtypeNorm.arff SRP 50 8 17 21\n",
      "X $1covtypeNorm.arff OBagAd 50 2 3 4\n",
      "X $1covtypeNorm.arff OBagAd 50 11 17 24\n",
      "X $1covtypeNorm.arff OBagAd 50 20 30 43\n",
      "X $1covtypeNorm.arff OBagASHT 50 2 4 4\n",
      "X $1covtypeNorm.arff OBagASHT 50 13 21 21\n",
      "X $1covtypeNorm.arff OBagASHT 50 23 38 38\n",
      "X $1covtypeNorm.arff OBag 50 3 3 4\n",
      "X $1covtypeNorm.arff OBag 50 15 19 21\n",
      "X $1covtypeNorm.arff OBag 50 27 35 38\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "26-01-2022\n",
      "esize 100\n",
      "bsize 500\n",
      "with incremental: True\n",
      "\n",
      "X $1GMSC.arff ARF 500 7 12 17\n",
      "X $1GMSC.arff ARF 500 35 62 89\n",
      "X $1GMSC.arff ARF 500 63 113 161\n",
      "X $1GMSC.arff LBag 500 8 14 23\n",
      "X $1GMSC.arff LBag 500 42 74 117\n",
      "X $1GMSC.arff LBag 500 77 134 210\n",
      "X $1GMSC.arff SRP 500 3 7 9\n",
      "X $1GMSC.arff SRP 500 19 36 48\n",
      "X $1GMSC.arff SRP 500 35 65 87\n",
      "X $1GMSC.arff OBagAd 500 23 26 60\n",
      "X $1GMSC.arff OBagAd 500 116 130 303\n",
      "X $1GMSC.arff OBagAd 500 210 235 546\n",
      "X $1GMSC.arff OBagASHT 500 34 34 96\n",
      "X $1GMSC.arff OBagASHT 500 170 172 484\n",
      "X $1GMSC.arff OBagASHT 500 307 309 871\n",
      "X $1GMSC.arff OBag 500 30 28 72\n",
      "X $1GMSC.arff OBag 500 153 140 362\n",
      "X $1GMSC.arff OBag 500 276 253 652\n",
      "X $1elecNormNew.arff ARF 500 3 8 10\n",
      "X $1elecNormNew.arff ARF 500 18 43 50\n",
      "X $1elecNormNew.arff ARF 500 33 78 91\n",
      "X $1elecNormNew.arff LBag 500 5 12 19\n",
      "X $1elecNormNew.arff LBag 500 29 64 98\n",
      "X $1elecNormNew.arff LBag 500 53 116 177\n",
      "X $1elecNormNew.arff SRP 500 2 4 6\n",
      "X $1elecNormNew.arff SRP 500 12 22 30\n",
      "X $1elecNormNew.arff SRP 500 22 40 54\n",
      "X $1elecNormNew.arff OBagAd 500 17 20 45\n",
      "X $1elecNormNew.arff OBagAd 500 89 102 228\n",
      "X $1elecNormNew.arff OBagAd 500 161 184 411\n",
      "X $1elecNormNew.arff OBagASHT 500 17 22 48\n",
      "X $1elecNormNew.arff OBagASHT 500 89 112 244\n",
      "X $1elecNormNew.arff OBagASHT 500 161 201 440\n",
      "X $1elecNormNew.arff OBag 500 24 26 53\n",
      "X $1elecNormNew.arff OBag 500 121 131 266\n",
      "X $1elecNormNew.arff OBag 500 218 237 479\n",
      "X $1covtypeNorm.arff ARF 500 2 6 7\n",
      "X $1covtypeNorm.arff ARF 500 11 31 36\n",
      "X $1covtypeNorm.arff ARF 500 20 56 66\n",
      "X $1covtypeNorm.arff LBag 500 2 3 4\n",
      "X $1covtypeNorm.arff LBag 500 10 17 21\n",
      "X $1covtypeNorm.arff LBag 500 18 31 38\n",
      "X $1covtypeNorm.arff SRP 500 0 1 2\n",
      "X $1covtypeNorm.arff SRP 500 4 9 12\n",
      "X $1covtypeNorm.arff SRP 500 8 17 21\n",
      "X $1covtypeNorm.arff OBagAd 500 2 3 3\n",
      "X $1covtypeNorm.arff OBagAd 500 11 17 19\n",
      "X $1covtypeNorm.arff OBagAd 500 20 30 34\n",
      "X $1covtypeNorm.arff OBagASHT 500 2 4 5\n",
      "X $1covtypeNorm.arff OBagASHT 500 13 21 29\n",
      "X $1covtypeNorm.arff OBagASHT 500 23 38 52\n",
      "X $1covtypeNorm.arff OBag 500 3 3 4\n",
      "X $1covtypeNorm.arff OBag 500 15 19 22\n",
      "X $1covtypeNorm.arff OBag 500 27 35 41\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "26-01-2022\n",
      "esize 100\n",
      "bsize 2000\n",
      "with incremental: True\n",
      "\n",
      "X $1GMSC.arff ARF 2000 7 12 15\n",
      "X $1GMSC.arff ARF 2000 35 62 79\n",
      "X $1GMSC.arff ARF 2000 63 113 143\n",
      "X $1GMSC.arff LBag 2000 8 14 21\n",
      "X $1GMSC.arff LBag 2000 42 74 105\n",
      "X $1GMSC.arff LBag 2000 77 134 189\n",
      "X $1GMSC.arff SRP 2000 3 7 9\n",
      "X $1GMSC.arff SRP 2000 19 36 47\n",
      "X $1GMSC.arff SRP 2000 35 65 84\n",
      "X $1GMSC.arff OBagAd 2000 23 26 55\n",
      "X $1GMSC.arff OBagAd 2000 116 130 278\n",
      "X $1GMSC.arff OBagAd 2000 210 235 502\n",
      "X $1GMSC.arff OBagASHT 2000 34 34 82\n",
      "X $1GMSC.arff OBagASHT 2000 170 172 411\n",
      "X $1GMSC.arff OBagASHT 2000 307 309 740\n",
      "X $1GMSC.arff OBag 2000 30 28 65\n",
      "X $1GMSC.arff OBag 2000 153 140 329\n",
      "X $1GMSC.arff OBag 2000 276 253 593\n",
      "X $1elecNormNew.arff ARF 2000 3 8 9\n",
      "X $1elecNormNew.arff ARF 2000 18 43 49\n",
      "X $1elecNormNew.arff ARF 2000 33 78 89\n",
      "X $1elecNormNew.arff LBag 2000 5 12 18\n",
      "X $1elecNormNew.arff LBag 2000 29 64 91\n",
      "X $1elecNormNew.arff LBag 2000 53 116 164\n",
      "X $1elecNormNew.arff SRP 2000 2 4 6\n",
      "X $1elecNormNew.arff SRP 2000 12 22 31\n",
      "X $1elecNormNew.arff SRP 2000 22 40 56\n",
      "X $1elecNormNew.arff OBagAd 2000 17 20 42\n",
      "X $1elecNormNew.arff OBagAd 2000 89 102 214\n",
      "X $1elecNormNew.arff OBagAd 2000 161 184 386\n",
      "X $1elecNormNew.arff OBagASHT 2000 17 22 46\n",
      "X $1elecNormNew.arff OBagASHT 2000 89 112 231\n",
      "X $1elecNormNew.arff OBagASHT 2000 161 201 416\n",
      "X $1elecNormNew.arff OBag 2000 24 26 50\n",
      "X $1elecNormNew.arff OBag 2000 121 131 251\n",
      "X $1elecNormNew.arff OBag 2000 218 237 452\n",
      "X $1covtypeNorm.arff ARF 2000 2 6 6\n",
      "X $1covtypeNorm.arff ARF 2000 11 31 30\n",
      "X $1covtypeNorm.arff ARF 2000 20 56 54\n",
      "X $1covtypeNorm.arff LBag 2000 2 3 4\n",
      "X $1covtypeNorm.arff LBag 2000 10 17 23\n",
      "X $1covtypeNorm.arff LBag 2000 18 31 42\n",
      "X $1covtypeNorm.arff SRP 2000 0 1 2\n",
      "X $1covtypeNorm.arff SRP 2000 4 9 13\n",
      "X $1covtypeNorm.arff SRP 2000 8 17 24\n",
      "X $1covtypeNorm.arff OBagAd 2000 2 3 4\n",
      "X $1covtypeNorm.arff OBagAd 2000 11 17 24\n",
      "X $1covtypeNorm.arff OBagAd 2000 20 30 43\n",
      "X $1covtypeNorm.arff OBagASHT 2000 2 4 6\n",
      "X $1covtypeNorm.arff OBagASHT 2000 13 21 30\n",
      "X $1covtypeNorm.arff OBagASHT 2000 23 38 54\n",
      "X $1covtypeNorm.arff OBag 2000 3 3 4\n",
      "X $1covtypeNorm.arff OBag 2000 15 19 24\n",
      "X $1covtypeNorm.arff OBag 2000 27 35 43\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_7820/1232116270.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df[\"algorithm\"].str.replace(\"OB$\", \"OBSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_7820/1232116270.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df[\"algorithm\"].str.replace(\"ARF$\", \"ARFSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_7820/1232116270.py:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df['algorithm'].str.replace(\"Adwin$\", \"AdwinSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_7820/1232116270.py:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df['algorithm'].str.replace(\"SRP$\", \"SRPSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_7820/1232116270.py:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df['algorithm'].str.replace(\"OBASHT$\", \"OBASHTSequential\")\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching/\n",
    "\n",
    "for i in range(len(moaDumpFolders)):\n",
    "    architecture=moaDumpFolders[i].split('/')[0]\n",
    "    print(f\"------------------------------ {architecture} ------------------------------ \")\n",
    "    parse_folder_to_file(f\"results/{moaDumpFolders[i]}\", f\"parsed_csvs/{wantedCSVfilename[i]}\")\n",
    "    calculate_rate_csv(f'parsed_csvs/{wantedCSVfilename[i]}', architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
