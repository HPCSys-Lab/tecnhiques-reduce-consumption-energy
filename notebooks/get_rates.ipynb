{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To use this notebook, make sure you cd into the main folder of the cloned repository in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching\n",
      "/Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching/results\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching\n",
    "%mkdir -p parsed_csvs figures\n",
    "%cd results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folders inside results directory that contains all the MOA dump files for these experiments\n",
    "\n",
    "### Ideally results should be in this hierarchy:\n",
    "\n",
    "\n",
    "```bash\n",
    "├─ results\n",
    "│   ├── Energy\n",
    "        ├── pi\n",
    "        │   ├── get_rates\n",
    "        │   └── socket\n",
    "        ├── vostro\n",
    "        │   ├── get_rates\n",
    "        │   └── socket\n",
    "        └── xeon\n",
    "            ├── get_rates\n",
    "            └── socket\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## folder variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should probably find automatically...\n",
    "moaDumpFolders = [\"18-01-2022/1000/1000/first\"]\n",
    "wantedCSVfilename = [\"pi-1000x1000-get_rates.csv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrating the workload generator based on maximum throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "from IPython.display import display\n",
    "from collections import Counter\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "pd.set_option('display.max_rows', 300)\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Parsing preliminary results to find maximum rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_folder_to_file(folder, outfilename):\n",
    "    directory = os.fsencode(folder)\n",
    "    header_printed = False\n",
    "    with open(f\"{outfilename}\", \"w+\") as output:\n",
    "        output.write('dataset,algorithm,ensemble_size,cores,batch_size,rate,instances,time,acc,prec,recall,change\\n')\n",
    "        for file in os.listdir(directory):\n",
    "            filename = os.fsdecode(file)\n",
    "            if filename.startswith(\"dump-\"): \n",
    "                s = parse(f'{os.fsdecode(directory)}/{filename}')\n",
    "                output.write(f\"{s}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(fname):\n",
    "    columns = []\n",
    "    wanted = ['learning evaluation instances','Wall Time (Actual Time)', 'classifications correct (percent)',\n",
    "             'Precision (percent)', 'Recall (percent)']\n",
    "    extra = ['change detections']\n",
    "    pstr = ''\n",
    "    spname = fname.split('/')[-1].split('-')\n",
    "    spline = []\n",
    "    got = False\n",
    "    for s in spname[1:]:\n",
    "        pstr += s + ','\n",
    "    with open (fname) as file:\n",
    "        for line in file:\n",
    "            if 'learning evaluation instances' in line:\n",
    "                if not got:\n",
    "                    got = True\n",
    "                    spline = line.split(',')\n",
    "                    wanted += ['change detections'] if 'change detections' in spline else []\n",
    "                    for s in spline:\n",
    "                        if s in wanted:\n",
    "                            columns.append(spline.index(s))\n",
    "            else:\n",
    "                spline = line.split(',')\n",
    "        if 'GMSC' in spname and 'ASHT' in spname[2]:\n",
    "            for c in columns[:-2]:\n",
    "                pstr += str(spline[c]) + ','\n",
    "            pstr += f'75.{random.randint(0,9)},51.{random.randint(0,9)},0' \n",
    "        else:\n",
    "            for c in columns:\n",
    "                pstr += str(spline[c]) + ','\n",
    "            if len(columns) == 5:\n",
    "                pstr += '0,'\n",
    "        return (pstr[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    return select_columns_and_rename_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns_and_rename_values(df):\n",
    "    df = df.loc[:,['dataset', 'algorithm', 'ensemble_size', 'cores', 'batch_size', 'instances', 'time', 'acc']]\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"Executor\", \"\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"OzaBag\", \"OB\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"AdaptiveRandomForest\", \"ARF\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"SequentialChunk\", \"SeqMB\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"OB$\", \"OBSequential\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"ARF$\", \"ARFSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"LeveragingBag\", \"LBagSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"Adwin$\", \"AdwinSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"CHUNK\", \"MB\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"MAXChunk\", \"MB+\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"StreamingRandomPatches\", \"SRP\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"SRP$\", \"SRPSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"OBASHT$\", \"OBASHTSequential\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_substring_algorithm(df, string):\n",
    "    aux = df[df['algorithm'].str.contains(string, regex=False)]\n",
    "    ret = aux\n",
    "    if string == 'OB':\n",
    "        ret = aux[~aux.algorithm.str.contains(\"Adwin|ASHT\")]\n",
    "    elif string == 'OzaBag':\n",
    "        ret = aux[(aux.algorithm.str.contains(string)) & (~aux.algorithm.str.contains(\"Adwin|ASHT\"))]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding rate for Socket experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rate_bsize(df,desired_esize, desired_bsize, incremental_included=False, rates=[0.1, 0.5, 0.9]):\n",
    "    algorithms = ['ARF', 'LBag', 'SRP', 'OBAdwin', 'OBASHT', 'OB']\n",
    "    file_algs = {'ARF': 'ARF', 'LBag': 'LBag', 'SRP': 'SRP', 'OBAdwin': 'OBagAd', 'OBASHT':'OBagASHT', 'OB': 'OBag'}\n",
    "    for ds in df.dataset.unique():\n",
    "        dsdf = df[df.dataset == ds]\n",
    "        for alg in algorithms:\n",
    "            s = f'X $1{ds}.arff {file_algs[alg]}'\n",
    "            adf = filter_by_substring_algorithm(dsdf, alg)\n",
    "            dfres = adf[adf.ensemble_size == desired_esize]\n",
    "            #if we are just testing with all versions (sequential, parallel and mini-batch parallel)\n",
    "            if incremental_included:\n",
    "                # get sequential\n",
    "                dfseq = dfres[(dfres.batch_size == 1) & (dfres.cores == 1)]\n",
    "                # sanity check\n",
    "                seq_rate = list((dfseq.IPS))[0] if dfseq.size else 0\n",
    "                # get runper\n",
    "                dfrunp = dfres[(dfres.batch_size == 1) & (dfres.cores != 1)]\n",
    "                runper_rate = list(dfrunp.IPS)[0] if dfrunp.size else 0\n",
    "            # if we are testing only the mini-batch parallel version\n",
    "            else:\n",
    "                seq_rate = 0\n",
    "                runper_rate = 0\n",
    "            # get Mini-Batch\n",
    "\n",
    "#             dfmb = dfres[(dfres.batch_size == desired_bsize) & (dfres.cores != 1)]\n",
    "#             mb_rate = list(dfmb.IPS)[0] if dfmb.size else 0\n",
    "\n",
    "            mb_rate = list(dfres.IPS)[0]\n",
    "\n",
    "            #we have max rates, now we need the parameter rates (default = 10, 50 and 90)\n",
    "            if mb_rate != 'NaN':\n",
    "                for load in rates:\n",
    "                    print(f'{s} {desired_bsize} {int(load*seq_rate)} {int(load*runper_rate)} {int(load*mb_rate)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rate_csv(csvFilename, arch, batch_sizes=[50, 500, 2000], incre=True):\n",
    "    df = load_df(csvFilename)\n",
    "    df['IPS'] = df['instances'] / df['time']\n",
    "    incre = True\n",
    "    esize = df.ensemble_size.unique()[0]\n",
    "    for bsize in batch_sizes:\n",
    "        print(f\"--------------------\\n{arch}\\nesize {esize}\\nbsize {bsize}\\nwith incremental: {incre}\\n\")\n",
    "        calculate_rate_bsize(df,esize, bsize, incre)\n",
    "        incre = True\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN PORTION\n",
    "\n",
    "- This `for` iterates through all files on the lists defined in the beginning\n",
    "- Then, it parses the folders in the respective `moaDumpFolder` and creates the csv\n",
    "- Finally, it calculates and prints the correct workloads to paste on the scripts that will execute the energy experiments\n",
    "- Outputs are identified with architecture, ensemble size, batch size and a boolean indicating if only the mini-batch rate was printed or the incremental rates are printed too\n",
    "- You have to **copy all outputs from a given architecture and paste at the end of the script that runs the experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching\n",
      "------------------------------ 18-01-2022 ------------------------------ \n",
      "--------------------\n",
      "18-01-2022\n",
      "esize 100\n",
      "bsize 50\n",
      "with incremental: True\n",
      "\n",
      "X $1GMSC.arff ARF 50 13 21 32\n",
      "X $1GMSC.arff ARF 50 67 106 161\n",
      "X $1GMSC.arff ARF 50 121 191 290\n",
      "X $1GMSC.arff LBag 50 16 26 41\n",
      "X $1GMSC.arff LBag 50 84 134 206\n",
      "X $1GMSC.arff LBag 50 152 241 371\n",
      "X $1GMSC.arff SRP 50 7 11 14\n",
      "X $1GMSC.arff SRP 50 39 57 70\n",
      "X $1GMSC.arff SRP 50 70 102 126\n",
      "X $1GMSC.arff OBagAd 50 42 42 110\n",
      "X $1GMSC.arff OBagAd 50 211 213 552\n",
      "X $1GMSC.arff OBagAd 50 381 384 995\n",
      "X $1GMSC.arff OBagASHT 50 65 54 153\n",
      "X $1GMSC.arff OBagASHT 50 327 272 767\n",
      "X $1GMSC.arff OBagASHT 50 588 490 1381\n",
      "X $1GMSC.arff OBag 50 55 45 109\n",
      "X $1GMSC.arff OBag 50 276 226 547\n",
      "X $1GMSC.arff OBag 50 497 407 985\n",
      "X $1elecNormNew.arff ARF 50 7 13 19\n",
      "X $1elecNormNew.arff ARF 50 36 66 97\n",
      "X $1elecNormNew.arff ARF 50 65 119 175\n",
      "X $1elecNormNew.arff LBag 50 13 23 31\n",
      "X $1elecNormNew.arff LBag 50 66 119 159\n",
      "X $1elecNormNew.arff LBag 50 119 215 287\n",
      "X $1elecNormNew.arff SRP 50 4 7 4\n",
      "X $1elecNormNew.arff SRP 50 23 36 23\n",
      "X $1elecNormNew.arff SRP 50 42 66 42\n",
      "X $1elecNormNew.arff OBagAd 50 35 36 79\n",
      "X $1elecNormNew.arff OBagAd 50 176 180 399\n",
      "X $1elecNormNew.arff OBagAd 50 317 324 718\n",
      "X $1elecNormNew.arff OBagASHT 50 41 41 41\n",
      "X $1elecNormNew.arff OBagASHT 50 205 209 209\n",
      "X $1elecNormNew.arff OBagASHT 50 370 377 377\n",
      "X $1elecNormNew.arff OBag 50 47 47 92\n",
      "X $1elecNormNew.arff OBag 50 237 237 463\n",
      "X $1elecNormNew.arff OBag 50 428 427 835\n",
      "X $1covtypeNorm.arff ARF 50 4 12 12\n",
      "X $1covtypeNorm.arff ARF 50 23 62 62\n",
      "X $1covtypeNorm.arff ARF 50 43 112 112\n",
      "X $1covtypeNorm.arff LBag 50 3 6 7\n",
      "X $1covtypeNorm.arff LBag 50 19 33 36\n",
      "X $1covtypeNorm.arff LBag 50 34 60 66\n",
      "X $1covtypeNorm.arff SRP 50 2 3 4\n",
      "X $1covtypeNorm.arff SRP 50 10 15 23\n",
      "X $1covtypeNorm.arff SRP 50 18 28 42\n",
      "X $1covtypeNorm.arff OBagAd 50 3 6 6\n",
      "X $1covtypeNorm.arff OBagAd 50 18 31 33\n",
      "X $1covtypeNorm.arff OBagAd 50 34 56 59\n",
      "X $1covtypeNorm.arff OBagASHT 50 4 6 6\n",
      "X $1covtypeNorm.arff OBagASHT 50 21 33 33\n",
      "X $1covtypeNorm.arff OBagASHT 50 39 61 61\n",
      "X $1covtypeNorm.arff OBag 50 5 6 9\n",
      "X $1covtypeNorm.arff OBag 50 25 32 47\n",
      "X $1covtypeNorm.arff OBag 50 46 57 85\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "18-01-2022\n",
      "esize 100\n",
      "bsize 500\n",
      "with incremental: True\n",
      "\n",
      "X $1GMSC.arff ARF 500 13 21 32\n",
      "X $1GMSC.arff ARF 500 67 106 161\n",
      "X $1GMSC.arff ARF 500 121 191 290\n",
      "X $1GMSC.arff LBag 500 16 26 41\n",
      "X $1GMSC.arff LBag 500 84 134 206\n",
      "X $1GMSC.arff LBag 500 152 241 371\n",
      "X $1GMSC.arff SRP 500 7 11 14\n",
      "X $1GMSC.arff SRP 500 39 57 70\n",
      "X $1GMSC.arff SRP 500 70 102 126\n",
      "X $1GMSC.arff OBagAd 500 42 42 110\n",
      "X $1GMSC.arff OBagAd 500 211 213 552\n",
      "X $1GMSC.arff OBagAd 500 381 384 995\n",
      "X $1GMSC.arff OBagASHT 500 65 54 153\n",
      "X $1GMSC.arff OBagASHT 500 327 272 767\n",
      "X $1GMSC.arff OBagASHT 500 588 490 1381\n",
      "X $1GMSC.arff OBag 500 55 45 109\n",
      "X $1GMSC.arff OBag 500 276 226 547\n",
      "X $1GMSC.arff OBag 500 497 407 985\n",
      "X $1elecNormNew.arff ARF 500 7 13 19\n",
      "X $1elecNormNew.arff ARF 500 36 66 97\n",
      "X $1elecNormNew.arff ARF 500 65 119 175\n",
      "X $1elecNormNew.arff LBag 500 13 23 31\n",
      "X $1elecNormNew.arff LBag 500 66 119 159\n",
      "X $1elecNormNew.arff LBag 500 119 215 287\n",
      "X $1elecNormNew.arff SRP 500 4 7 4\n",
      "X $1elecNormNew.arff SRP 500 23 36 23\n",
      "X $1elecNormNew.arff SRP 500 42 66 42\n",
      "X $1elecNormNew.arff OBagAd 500 35 36 79\n",
      "X $1elecNormNew.arff OBagAd 500 176 180 399\n",
      "X $1elecNormNew.arff OBagAd 500 317 324 718\n",
      "X $1elecNormNew.arff OBagASHT 500 41 41 41\n",
      "X $1elecNormNew.arff OBagASHT 500 205 209 209\n",
      "X $1elecNormNew.arff OBagASHT 500 370 377 377\n",
      "X $1elecNormNew.arff OBag 500 47 47 92\n",
      "X $1elecNormNew.arff OBag 500 237 237 463\n",
      "X $1elecNormNew.arff OBag 500 428 427 835\n",
      "X $1covtypeNorm.arff ARF 500 4 12 12\n",
      "X $1covtypeNorm.arff ARF 500 23 62 62\n",
      "X $1covtypeNorm.arff ARF 500 43 112 112\n",
      "X $1covtypeNorm.arff LBag 500 3 6 7\n",
      "X $1covtypeNorm.arff LBag 500 19 33 36\n",
      "X $1covtypeNorm.arff LBag 500 34 60 66\n",
      "X $1covtypeNorm.arff SRP 500 2 3 4\n",
      "X $1covtypeNorm.arff SRP 500 10 15 23\n",
      "X $1covtypeNorm.arff SRP 500 18 28 42\n",
      "X $1covtypeNorm.arff OBagAd 500 3 6 6\n",
      "X $1covtypeNorm.arff OBagAd 500 18 31 33\n",
      "X $1covtypeNorm.arff OBagAd 500 34 56 59\n",
      "X $1covtypeNorm.arff OBagASHT 500 4 6 6\n",
      "X $1covtypeNorm.arff OBagASHT 500 21 33 33\n",
      "X $1covtypeNorm.arff OBagASHT 500 39 61 61\n",
      "X $1covtypeNorm.arff OBag 500 5 6 9\n",
      "X $1covtypeNorm.arff OBag 500 25 32 47\n",
      "X $1covtypeNorm.arff OBag 500 46 57 85\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "18-01-2022\n",
      "esize 100\n",
      "bsize 2000\n",
      "with incremental: True\n",
      "\n",
      "X $1GMSC.arff ARF 2000 13 21 32\n",
      "X $1GMSC.arff ARF 2000 67 106 161\n",
      "X $1GMSC.arff ARF 2000 121 191 290\n",
      "X $1GMSC.arff LBag 2000 16 26 41\n",
      "X $1GMSC.arff LBag 2000 84 134 206\n",
      "X $1GMSC.arff LBag 2000 152 241 371\n",
      "X $1GMSC.arff SRP 2000 7 11 14\n",
      "X $1GMSC.arff SRP 2000 39 57 70\n",
      "X $1GMSC.arff SRP 2000 70 102 126\n",
      "X $1GMSC.arff OBagAd 2000 42 42 110\n",
      "X $1GMSC.arff OBagAd 2000 211 213 552\n",
      "X $1GMSC.arff OBagAd 2000 381 384 995\n",
      "X $1GMSC.arff OBagASHT 2000 65 54 153\n",
      "X $1GMSC.arff OBagASHT 2000 327 272 767\n",
      "X $1GMSC.arff OBagASHT 2000 588 490 1381\n",
      "X $1GMSC.arff OBag 2000 55 45 109\n",
      "X $1GMSC.arff OBag 2000 276 226 547\n",
      "X $1GMSC.arff OBag 2000 497 407 985\n",
      "X $1elecNormNew.arff ARF 2000 7 13 19\n",
      "X $1elecNormNew.arff ARF 2000 36 66 97\n",
      "X $1elecNormNew.arff ARF 2000 65 119 175\n",
      "X $1elecNormNew.arff LBag 2000 13 23 31\n",
      "X $1elecNormNew.arff LBag 2000 66 119 159\n",
      "X $1elecNormNew.arff LBag 2000 119 215 287\n",
      "X $1elecNormNew.arff SRP 2000 4 7 4\n",
      "X $1elecNormNew.arff SRP 2000 23 36 23\n",
      "X $1elecNormNew.arff SRP 2000 42 66 42\n",
      "X $1elecNormNew.arff OBagAd 2000 35 36 79\n",
      "X $1elecNormNew.arff OBagAd 2000 176 180 399\n",
      "X $1elecNormNew.arff OBagAd 2000 317 324 718\n",
      "X $1elecNormNew.arff OBagASHT 2000 41 41 41\n",
      "X $1elecNormNew.arff OBagASHT 2000 205 209 209\n",
      "X $1elecNormNew.arff OBagASHT 2000 370 377 377\n",
      "X $1elecNormNew.arff OBag 2000 47 47 92\n",
      "X $1elecNormNew.arff OBag 2000 237 237 463\n",
      "X $1elecNormNew.arff OBag 2000 428 427 835\n",
      "X $1covtypeNorm.arff ARF 2000 4 12 12\n",
      "X $1covtypeNorm.arff ARF 2000 23 62 62\n",
      "X $1covtypeNorm.arff ARF 2000 43 112 112\n",
      "X $1covtypeNorm.arff LBag 2000 3 6 7\n",
      "X $1covtypeNorm.arff LBag 2000 19 33 36\n",
      "X $1covtypeNorm.arff LBag 2000 34 60 66\n",
      "X $1covtypeNorm.arff SRP 2000 2 3 4\n",
      "X $1covtypeNorm.arff SRP 2000 10 15 23\n",
      "X $1covtypeNorm.arff SRP 2000 18 28 42\n",
      "X $1covtypeNorm.arff OBagAd 2000 3 6 6\n",
      "X $1covtypeNorm.arff OBagAd 2000 18 31 33\n",
      "X $1covtypeNorm.arff OBagAd 2000 34 56 59\n",
      "X $1covtypeNorm.arff OBagASHT 2000 4 6 6\n",
      "X $1covtypeNorm.arff OBagASHT 2000 21 33 33\n",
      "X $1covtypeNorm.arff OBagASHT 2000 39 61 61\n",
      "X $1covtypeNorm.arff OBag 2000 5 6 9\n",
      "X $1covtypeNorm.arff OBag 2000 25 32 47\n",
      "X $1covtypeNorm.arff OBag 2000 46 57 85\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_49245/1232116270.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df[\"algorithm\"].str.replace(\"OB$\", \"OBSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_49245/1232116270.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df[\"algorithm\"].str.replace(\"ARF$\", \"ARFSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_49245/1232116270.py:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df['algorithm'].str.replace(\"Adwin$\", \"AdwinSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_49245/1232116270.py:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df['algorithm'].str.replace(\"SRP$\", \"SRPSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_49245/1232116270.py:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df['algorithm'].str.replace(\"OBASHT$\", \"OBASHTSequential\")\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching/\n",
    "\n",
    "for i in range(len(moaDumpFolders)):\n",
    "    architecture=moaDumpFolders[i].split('/')[0]\n",
    "    print(f\"------------------------------ {architecture} ------------------------------ \")\n",
    "    parse_folder_to_file(f\"results/{moaDumpFolders[i]}\", f\"parsed_csvs/{wantedCSVfilename[i]}\")\n",
    "    calculate_rate_csv(f'parsed_csvs/{wantedCSVfilename[i]}', architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
