{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a81a67d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "from IPython.display import display\n",
    "from collections import Counter\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "pd.set_option('display.max_rows', 300)\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20d28ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads the csv as a dataframe and standardizes the algorithm names \n",
    "def load_df(filename):\n",
    "    df = pd.read_csv(filename, index_col=False)\n",
    "    return select_columns_and_rename_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8852756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filters by substring (there are multiple OzaBag algorithms)\n",
    "def filter_by_substring_algorithm(df, string):\n",
    "    aux = df[df['algorithm'].str.contains(string, regex=False)]\n",
    "    ret = aux\n",
    "    if string == 'OB':\n",
    "        ret = aux[~aux.algorithm.str.contains(\"Adwin|ASHT\")]\n",
    "    elif string == 'OzaBag':\n",
    "        ret = aux[(aux.algorithm.str.contains(string)) & (~aux.algorithm.str.contains(\"Adwin|ASHT\"))]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d8d3fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize algorithm names\n",
    "def select_columns_and_rename_values(df):\n",
    "    df.algorithm = df.algorithm.str.replace(\"Executor\", \"\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"OzaBag\", \"OB\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"AdaptiveRandomForest\", \"ARF\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"SequentialChunk\", \"SeqMB\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"OB$\", \"OBSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"LeveragingBag\", \"LBagSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"Adwin$\", \"AdwinSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"CHUNK\", \"MB\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"MAXChunk\", \"MB\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"StreamingRandomPatches\", \"SRP\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"SRP$\", \"SRPSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"OBASHT$\", \"OBASHTSequential\")\n",
    "    df.batch_size.unique()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0da42d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching\n"
     ]
    }
   ],
   "source": [
    "#Folder inside results directory that contains all the MOA dump files for these experiments\n",
    "%cd /Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching/\n",
    "folderMOADumps = \"/Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching/results/optimized/speedup/08-07-2022/loop-fusion-all-algorithms-speedup\"\n",
    "wantedCSVfilename = \"speedup-pi-loop-fusion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "664f157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_speedup(fname):\n",
    "    global header_printed\n",
    "    #index of wanted columns\n",
    "    columns = []\n",
    "    #column names to get the data from\n",
    "    wanted = ['learning evaluation instances','Wall Time (Actual Time)', 'classifications correct (percent)',\n",
    "             'Precision (percent)', 'Recall (percent)']\n",
    "    extra = ['change detections']\n",
    "    ret_string = ''\n",
    "    #remove the path and isolate the filename\n",
    "    spname = fname.split('/')[-1].split('-')\n",
    "    spline = []\n",
    "    #control flag for knowing when the column names have already been discovered\n",
    "    got = False\n",
    "    #we ignore the first parameter of the filename and add all others to the csv string\n",
    "    for s in spname[1:]:\n",
    "        ret_string += s + ','\n",
    "    #should probably use a safer way, but python handles the closing of the file\n",
    "    with open (fname) as file:\n",
    "        for line in file:\n",
    "            if 'learning evaluation instances' in line:\n",
    "                #sometimes the dump file has multiple results in it, so we get the index of wanted columns only once\n",
    "                if not got:\n",
    "                    got = True\n",
    "                    spline = line.split(',')\n",
    "                    wanted += ['change detections'] if 'change detections' in spline else []\n",
    "                    for s in spline:\n",
    "                        if s in wanted:\n",
    "                            columns.append(spline.index(s))\n",
    "            else:\n",
    "                spline = line.split(',')\n",
    "        #OzaBagASHT bugs out on GMSC, this reuses the data from the sequential execution\n",
    "        if 'GMSC' in spname and 'ASHT' in spname[2]:\n",
    "            for c in columns[:-2]:\n",
    "                ret_string += str(spline[c]) + ','\n",
    "            ret_string += f'75.{random.randint(0,9)},51.{random.randint(0,9)},0' \n",
    "        #normal code, how everything should run\n",
    "        #we process the data (add the content of wanted columns to the csv string) only after the for\n",
    "        #ensuring we use only the last (most recent) data and not the intermediate results\n",
    "        else:\n",
    "            for c in columns:\n",
    "                ret_string += str(spline[c]) + ','\n",
    "            if len(columns) == 5:\n",
    "                ret_string += '0,'\n",
    "        #header is a global variable, it will only be printed on the first file \n",
    "        if not header_printed:\n",
    "            head = 'dataset,algorithm,ensemble_size,cores,batch_size,inc_rate,instances,time,acc,prec,recall'\n",
    "            ret_string = f\"{head}\\n{ret_string}\"\n",
    "            header_printed = True\n",
    "        #remove the last comma ,\n",
    "        return (ret_string[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8bb513a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4101183849.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [33]\u001b[0;36m\u001b[0m\n\u001b[0;31m    for df[algorithm]\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def find_sequential_value_by_index(df, algorithm):\n",
    "    for df[algorithm]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0273a543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_22909/2209187601.py:3: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  df = pd.read_csv(filename, index_col=False)\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_22909/3478987594.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df[\"algorithm\"].str.replace(\"OB$\", \"OBSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_22909/3478987594.py:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df['algorithm'].str.replace(\"Adwin$\", \"AdwinSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_22909/3478987594.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df['algorithm'].str.replace(\"SRP$\", \"SRPSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_22909/3478987594.py:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df['algorithm'].str.replace(\"OBASHT$\", \"OBASHTSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_22909/2209187601.py:3: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  df = pd.read_csv(filename, index_col=False)\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_22909/3478987594.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df[\"algorithm\"].str.replace(\"OB$\", \"OBSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_22909/3478987594.py:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df['algorithm'].str.replace(\"Adwin$\", \"AdwinSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_22909/3478987594.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df['algorithm'].str.replace(\"SRP$\", \"SRPSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_22909/3478987594.py:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df['algorithm'].str.replace(\"OBASHT$\", \"OBASHTSequential\")\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "find_sequential_value_by_index() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m             df_speedup[row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m]][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msequential\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     53\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     54\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malgorithm\u001b[39m\u001b[38;5;124m'\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malgorithm\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     61\u001b[0m             })\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m             \u001b[43mfind_sequential_value_by_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_speedup\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msequential\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_to\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43malgorithm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m             df_speedup[row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m]][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloop_fusion\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     65\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     66\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malgorithm\u001b[39m\u001b[38;5;124m'\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malgorithm\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     73\u001b[0m             })\n\u001b[1;32m     75\u001b[0m df_speedup \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(df_speedup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mairlines\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloop_fusion\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: find_sequential_value_by_index() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "df_speedup = {\n",
    "    'airlines': {\n",
    "        'sequential': [],\n",
    "        'loop_fusion': []\n",
    "    },\n",
    "    'GMSC': {\n",
    "        'sequential': [],\n",
    "        'loop_fusion': []\n",
    "    },\n",
    "    'covtypeNorm': {\n",
    "        'sequential': [],\n",
    "        'loop_fusion': []\n",
    "    },\n",
    "    'elecNormNew': {\n",
    "        'sequential': [],\n",
    "        'loop_fusion': []\n",
    "    }\n",
    "}\n",
    "\n",
    "from_to = {\n",
    "    'LBagMB': 'LBagSequential',\n",
    "    'ARFMB': 'ARFSequential',\n",
    "    'OBAdwinMB': 'OBAdwinSequential',\n",
    "    'OBMB': 'OBSequential',\n",
    "    'OBASHTMB': 'OBASHTSequential',\n",
    "    'SRPMB': 'SRPSequential'\n",
    "}\n",
    "\n",
    "for cpu in list([1, 2, 3, 4]):\n",
    "    resultsFolder = f\"{folderMOADumps}/{str(cpu)}/first\"\n",
    "    csvFile = f\"parsed_csvs/{wantedCSVfilename}-{str(cpu)}.csv\"\n",
    "    directory = os.fsencode(resultsFolder)\n",
    "    header_printed = False\n",
    "\n",
    "    with open(f\"{csvFile}\", \"w+\") as output:\n",
    "        for file in os.listdir(directory):\n",
    "            filename = os.fsdecode(file)\n",
    "            if filename.startswith(\"dump-\"): \n",
    "                output.write(f\"{parse_speedup(f'{os.fsdecode(directory)}/{filename}')}\\n\")\n",
    "\n",
    "    df = load_df(f'{csvFile}')\n",
    "\n",
    "    for index, row in df[['dataset', 'algorithm', 'cores', 'acc', 'time', 'instances']].iterrows():\n",
    "#         if (row['dataset'] == 'airlines' and (row['algorithm'] == 'ARFSequential' or row['algorithm'] == 'ARFMB')):\n",
    "#             if (row['algorithm'] == 'ARFSequential'):\n",
    "\n",
    "#             else:\n",
    "#                 speedup = time_sequential_arf / row['time']\n",
    "#                 eficiency = speedup / row['cores']\n",
    " \n",
    "        if (\"Sequential\" in row['algorithm']):\n",
    "            df_speedup[row['dataset']]['sequential'].append({\n",
    "                'dataset': row['dataset'],\n",
    "                'algorithm': row['algorithm'],\n",
    "                'cores': row['cores'],\n",
    "                'time': row['time'],\n",
    "                'instances': row['instances'],\n",
    "                'speedup': speedup,\n",
    "                'eficiency': eficiency,\n",
    "                'acc': row['acc']\n",
    "            })\n",
    "        else:\n",
    "            find_sequential_value_by_index(df_speedup[row['dataset']]['sequential'], from_to[row['algorithm']])\n",
    "\n",
    "            df_speedup[row['dataset']]['loop_fusion'].append({\n",
    "                'dataset': row['dataset'],\n",
    "                'algorithm': row['algorithm'],\n",
    "                'cores': row['cores'],\n",
    "                'time': row['time'],\n",
    "                'instances': row['instances'],\n",
    "                'speedup': speedup,\n",
    "                'eficiency': eficiency,\n",
    "                'acc': row['acc']\n",
    "            })\n",
    "\n",
    "df_speedup = pd.DataFrame(df_speedup['airlines']['loop_fusion'])\n",
    "display(df_speedup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c3bdb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
