{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To use this notebook, make sure you cd into the main folder of the cloned repository in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching\n",
      "/Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching/results\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching\n",
    "%mkdir -p parsed_csvs figures\n",
    "%cd results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folders inside results directory that contains all the MOA dump files for these experiments\n",
    "\n",
    "### Ideally results should be in this hierarchy:\n",
    "\n",
    "\n",
    "```bash\n",
    "├─ results\n",
    "│   ├── Energy\n",
    "        ├── pi\n",
    "        │   ├── get_rates\n",
    "        │   └── socket\n",
    "        ├── vostro\n",
    "        │   ├── get_rates\n",
    "        │   └── socket\n",
    "        └── xeon\n",
    "            ├── get_rates\n",
    "            └── socket\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## folder variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should probably find automatically...\n",
    "\n",
    "moaDumpFolders = [\"loop-fusion/mini-batching/final/4/third\"]\n",
    "wantedCSVfilename = [\"pi-600x1200-get_rates.csv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrating the workload generator based on maximum throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "from IPython.display import display\n",
    "from collections import Counter\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "pd.set_option('display.max_rows', 300)\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Parsing preliminary results to find maximum rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_folder_to_file(folder, outfilename):\n",
    "    directory = os.fsencode(folder)\n",
    "    header_printed = False\n",
    "    with open(f\"{outfilename}\", \"w+\") as output:\n",
    "        output.write('dataset,algorithm,ensemble_size,cores,batch_size,rate,instances,time,acc,prec,recall,change\\n')\n",
    "        for file in os.listdir(directory):\n",
    "            filename = os.fsdecode(file)\n",
    "            if filename.startswith(\"dump-\"): \n",
    "                s = parse(f'{os.fsdecode(directory)}/{filename}')\n",
    "                output.write(f\"{s}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(fname):\n",
    "    columns = []\n",
    "    wanted = ['learning evaluation instances','Wall Time (Actual Time)', 'classifications correct (percent)',\n",
    "             'Precision (percent)', 'Recall (percent)']\n",
    "    extra = ['change detections']\n",
    "    pstr = ''\n",
    "    spname = fname.split('/')[-1].split('-')\n",
    "    spline = []\n",
    "    got = False\n",
    "    for s in spname[1:]:\n",
    "        pstr += s + ','\n",
    "    with open (fname) as file:\n",
    "        for line in file:\n",
    "            if 'learning evaluation instances' in line:\n",
    "                if not got:\n",
    "                    got = True\n",
    "                    spline = line.split(',')\n",
    "                    wanted += ['change detections'] if 'change detections' in spline else []\n",
    "                    for s in spline:\n",
    "                        if s in wanted:\n",
    "                            columns.append(spline.index(s))\n",
    "            else:\n",
    "                spline = line.split(',')\n",
    "        if 'GMSC' in spname and 'ASHT' in spname[2]:\n",
    "            for c in columns[:-2]:\n",
    "                pstr += str(spline[c]) + ','\n",
    "            pstr += f'75.{random.randint(0,9)},51.{random.randint(0,9)},0' \n",
    "        else:\n",
    "            for c in columns:\n",
    "                pstr += str(spline[c]) + ','\n",
    "            if len(columns) == 5:\n",
    "                pstr += '0,'\n",
    "        return (pstr[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    return select_columns_and_rename_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns_and_rename_values(df):\n",
    "    df = df.loc[:,['dataset', 'algorithm', 'ensemble_size', 'cores', 'batch_size', 'instances', 'time', 'acc']]\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"Executor\", \"\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"OzaBag\", \"OB\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"AdaptiveRandomForest\", \"ARF\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"SequentialChunk\", \"SeqMB\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"OB$\", \"OBSequential\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"ARF$\", \"ARFSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"LeveragingBag\", \"LBagSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"Adwin$\", \"AdwinSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"CHUNK\", \"MB\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"MAXChunk\", \"MB+\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"StreamingRandomPatches\", \"SRP\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"SRP$\", \"SRPSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"OBASHT$\", \"OBASHTSequential\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_substring_algorithm(df, string):\n",
    "    aux = df[df['algorithm'].str.contains(string, regex=False)]\n",
    "    ret = aux\n",
    "    if string == 'OB':\n",
    "        ret = aux[~aux.algorithm.str.contains(\"Adwin|ASHT\")]\n",
    "    elif string == 'OzaBag':\n",
    "        ret = aux[(aux.algorithm.str.contains(string)) & (~aux.algorithm.str.contains(\"Adwin|ASHT\"))]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding rate for Socket experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rate_bsize(df,desired_esize, desired_bsize, incremental_included=False, rates=[0.1, 0.5, 0.9]):\n",
    "    algorithms = ['ARF', 'LBag', 'SRP', 'OBAdwin', 'OBASHT', 'OB']\n",
    "    file_algs = {'ARF': 'ARF', 'LBag': 'LBag', 'SRP': 'SRP', 'OBAdwin': 'OBagAd', 'OBASHT':'OBagASHT', 'OB': 'OBag'}\n",
    "\n",
    "    for ds in df.dataset.unique():\n",
    "        dsdf = df[df.dataset == ds]\n",
    "        for alg in algorithms:\n",
    "            s = f'X $1{ds}.arff {file_algs[alg]}'\n",
    "            adf = filter_by_substring_algorithm(dsdf, alg)\n",
    "            dfres = adf[adf.ensemble_size == desired_esize]\n",
    "            #if we are just testing with all versions (sequential, parallel and mini-batch parallel)\n",
    "            if incremental_included:\n",
    "                # get sequential\n",
    "                dfseq = dfres[(dfres.batch_size == 1) & (dfres.cores == 1)]\n",
    "                # sanity check\n",
    "                seq_rate = list((dfseq.IPS))[0] if dfseq.size else 0\n",
    "                # get runper\n",
    "                dfrunp = dfres[(dfres.batch_size == 1) & (dfres.cores != 1)]\n",
    "                runper_rate = list(dfrunp.IPS)[0] if dfrunp.size else 0\n",
    "            # if we are testing only the mini-batch parallel version\n",
    "            else:\n",
    "                seq_rate = 0\n",
    "                runper_rate = 0\n",
    "            # get Mini-Batch\n",
    "            dfmb = dfres[(dfres.batch_size == desired_bsize) & (dfres.cores != 1)]\n",
    "            mb_rate = list(dfmb.IPS)[0] if dfmb.size else 0\n",
    "            #we have max rates, now we need the parameter rates (default = 10, 50 and 90)\n",
    "            if mb_rate != 'NaN':\n",
    "                for load in rates:\n",
    "                    print(f'{s} {desired_bsize} {int(load*seq_rate)} {int(load*runper_rate)} {int(load*mb_rate)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rate_csv(csvFilename, arch, batch_sizes=[25,50,75,100,250,500,2000], incre=True):\n",
    "    df = load_df(csvFilename)\n",
    "    df['IPS'] = df['instances'] / df['time']\n",
    "    incre = True\n",
    "    esize = df.ensemble_size.unique()[0]\n",
    "    for bsize in batch_sizes:\n",
    "        print(f\"--------------------\\n{arch}\\nesize {esize}\\nbsize {bsize}\\nwith incremental: {incre}\\n\")\n",
    "        calculate_rate_bsize(df,esize, bsize, incre)\n",
    "        incre = True\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN PORTION\n",
    "\n",
    "- This `for` iterates through all files on the lists defined in the beginning\n",
    "- Then, it parses the folders in the respective `moaDumpFolder` and creates the csv\n",
    "- Finally, it calculates and prints the correct workloads to paste on the scripts that will execute the energy experiments\n",
    "- Outputs are identified with architecture, ensemble size, batch size and a boolean indicating if only the mini-batch rate was printed or the incremental rates are printed too\n",
    "- You have to **copy all outputs from a given architecture and paste at the end of the script that runs the experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching\n",
      "------------------------------ loop-fusion ------------------------------ \n",
      "--------------------\n",
      "loop-fusion\n",
      "esize 25\n",
      "bsize 25\n",
      "with incremental: True\n",
      "\n",
      "X $1elecNormNew.arff ARF 25 31 45 79\n",
      "X $1elecNormNew.arff ARF 25 157 229 397\n",
      "X $1elecNormNew.arff ARF 25 284 413 714\n",
      "X $1covtypeNorm.arff ARF 25 21 38 88\n",
      "X $1covtypeNorm.arff ARF 25 105 192 441\n",
      "X $1covtypeNorm.arff ARF 25 189 346 793\n",
      "X $1airlines.arff ARF 25 6 17 22\n",
      "X $1airlines.arff ARF 25 33 85 110\n",
      "X $1airlines.arff ARF 25 60 154 198\n",
      "X $1GMSC.arff ARF 25 51 62 154\n",
      "X $1GMSC.arff ARF 25 257 312 771\n",
      "X $1GMSC.arff ARF 25 464 562 1389\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "loop-fusion\n",
      "esize 25\n",
      "bsize 50\n",
      "with incremental: True\n",
      "\n",
      "X $1elecNormNew.arff ARF 50 31 45 73\n",
      "X $1elecNormNew.arff ARF 50 157 229 365\n",
      "X $1elecNormNew.arff ARF 50 284 413 658\n",
      "X $1covtypeNorm.arff ARF 50 21 38 89\n",
      "X $1covtypeNorm.arff ARF 50 105 192 446\n",
      "X $1covtypeNorm.arff ARF 50 189 346 804\n",
      "X $1airlines.arff ARF 50 6 17 22\n",
      "X $1airlines.arff ARF 50 33 85 112\n",
      "X $1airlines.arff ARF 50 60 154 203\n",
      "X $1GMSC.arff ARF 50 51 62 147\n",
      "X $1GMSC.arff ARF 50 257 312 739\n",
      "X $1GMSC.arff ARF 50 464 562 1330\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "loop-fusion\n",
      "esize 25\n",
      "bsize 75\n",
      "with incremental: True\n",
      "\n",
      "X $1elecNormNew.arff ARF 75 31 45 72\n",
      "X $1elecNormNew.arff ARF 75 157 229 360\n",
      "X $1elecNormNew.arff ARF 75 284 413 649\n",
      "X $1covtypeNorm.arff ARF 75 21 38 102\n",
      "X $1covtypeNorm.arff ARF 75 105 192 514\n",
      "X $1covtypeNorm.arff ARF 75 189 346 925\n",
      "X $1airlines.arff ARF 75 6 17 23\n",
      "X $1airlines.arff ARF 75 33 85 116\n",
      "X $1airlines.arff ARF 75 60 154 210\n",
      "X $1GMSC.arff ARF 75 51 62 158\n",
      "X $1GMSC.arff ARF 75 257 312 791\n",
      "X $1GMSC.arff ARF 75 464 562 1424\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "loop-fusion\n",
      "esize 25\n",
      "bsize 100\n",
      "with incremental: True\n",
      "\n",
      "X $1elecNormNew.arff ARF 100 31 45 73\n",
      "X $1elecNormNew.arff ARF 100 157 229 365\n",
      "X $1elecNormNew.arff ARF 100 284 413 658\n",
      "X $1covtypeNorm.arff ARF 100 21 38 96\n",
      "X $1covtypeNorm.arff ARF 100 105 192 482\n",
      "X $1covtypeNorm.arff ARF 100 189 346 869\n",
      "X $1airlines.arff ARF 100 6 17 23\n",
      "X $1airlines.arff ARF 100 33 85 117\n",
      "X $1airlines.arff ARF 100 60 154 211\n",
      "X $1GMSC.arff ARF 100 51 62 162\n",
      "X $1GMSC.arff ARF 100 257 312 811\n",
      "X $1GMSC.arff ARF 100 464 562 1460\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "loop-fusion\n",
      "esize 25\n",
      "bsize 250\n",
      "with incremental: True\n",
      "\n",
      "X $1elecNormNew.arff ARF 250 31 45 80\n",
      "X $1elecNormNew.arff ARF 250 157 229 400\n",
      "X $1elecNormNew.arff ARF 250 284 413 721\n",
      "X $1covtypeNorm.arff ARF 250 21 38 94\n",
      "X $1covtypeNorm.arff ARF 250 105 192 472\n",
      "X $1covtypeNorm.arff ARF 250 189 346 849\n",
      "X $1airlines.arff ARF 250 6 17 25\n",
      "X $1airlines.arff ARF 250 33 85 128\n",
      "X $1airlines.arff ARF 250 60 154 230\n",
      "X $1GMSC.arff ARF 250 51 62 161\n",
      "X $1GMSC.arff ARF 250 257 312 806\n",
      "X $1GMSC.arff ARF 250 464 562 1451\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "loop-fusion\n",
      "esize 25\n",
      "bsize 500\n",
      "with incremental: True\n",
      "\n",
      "X $1elecNormNew.arff ARF 500 31 45 74\n",
      "X $1elecNormNew.arff ARF 500 157 229 373\n",
      "X $1elecNormNew.arff ARF 500 284 413 671\n",
      "X $1covtypeNorm.arff ARF 500 21 38 96\n",
      "X $1covtypeNorm.arff ARF 500 105 192 482\n",
      "X $1covtypeNorm.arff ARF 500 189 346 867\n",
      "X $1airlines.arff ARF 500 6 17 27\n",
      "X $1airlines.arff ARF 500 33 85 136\n",
      "X $1airlines.arff ARF 500 60 154 245\n",
      "X $1GMSC.arff ARF 500 51 62 165\n",
      "X $1GMSC.arff ARF 500 257 312 828\n",
      "X $1GMSC.arff ARF 500 464 562 1491\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "loop-fusion\n",
      "esize 25\n",
      "bsize 2000\n",
      "with incremental: True\n",
      "\n",
      "X $1elecNormNew.arff ARF 2000 31 45 64\n",
      "X $1elecNormNew.arff ARF 2000 157 229 323\n",
      "X $1elecNormNew.arff ARF 2000 284 413 582\n",
      "X $1covtypeNorm.arff ARF 2000 21 38 88\n",
      "X $1covtypeNorm.arff ARF 2000 105 192 444\n",
      "X $1covtypeNorm.arff ARF 2000 189 346 799\n",
      "X $1airlines.arff ARF 2000 6 17 28\n",
      "X $1airlines.arff ARF 2000 33 85 144\n",
      "X $1airlines.arff ARF 2000 60 154 259\n",
      "X $1GMSC.arff ARF 2000 51 62 168\n",
      "X $1GMSC.arff ARF 2000 257 312 842\n",
      "X $1GMSC.arff ARF 2000 464 562 1516\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_8339/1232116270.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df[\"algorithm\"].str.replace(\"OB$\", \"OBSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_8339/1232116270.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df[\"algorithm\"].str.replace(\"ARF$\", \"ARFSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_8339/1232116270.py:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df['algorithm'].str.replace(\"Adwin$\", \"AdwinSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_8339/1232116270.py:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df['algorithm'].str.replace(\"SRP$\", \"SRPSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_8339/1232116270.py:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df['algorithm'].str.replace(\"OBASHT$\", \"OBASHTSequential\")\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching/\n",
    "\n",
    "for i in range(len(moaDumpFolders)):\n",
    "    architecture=moaDumpFolders[i].split('/')[0]\n",
    "    print(f\"------------------------------ {architecture} ------------------------------ \")\n",
    "    parse_folder_to_file(f\"results/{moaDumpFolders[i]}\", f\"parsed_csvs/{wantedCSVfilename[i]}\")\n",
    "    calculate_rate_csv(f'parsed_csvs/{wantedCSVfilename[i]}', architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
