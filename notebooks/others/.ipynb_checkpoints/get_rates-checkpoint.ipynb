{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To use this notebook, make sure you cd into the main folder of the cloned repository in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching\n",
      "/Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching/results\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching\n",
    "%mkdir -p parsed_csvs figures\n",
    "%cd results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folders inside results directory that contains all the MOA dump files for these experiments\n",
    "\n",
    "### Ideally results should be in this hierarchy:\n",
    "\n",
    "\n",
    "```bash\n",
    "├─ results\n",
    "│   ├── Energy\n",
    "        ├── pi\n",
    "        │   ├── get_rates\n",
    "        │   └── socket\n",
    "        ├── vostro\n",
    "        │   ├── get_rates\n",
    "        │   └── socket\n",
    "        └── xeon\n",
    "            ├── get_rates\n",
    "            └── socket\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## folder variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should probably find automatically...\n",
    "\n",
    "moaDumpFolders = [\"loop-fusion/acc/loop-fusion-sequential\"]\n",
    "wantedCSVfilename = [\"pi-600x1200-get_rates.csv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrating the workload generator based on maximum throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "from IPython.display import display\n",
    "from collections import Counter\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "pd.set_option('display.max_rows', 300)\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Parsing preliminary results to find maximum rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_folder_to_file(folder, outfilename):\n",
    "    directory = os.fsencode(folder)\n",
    "    header_printed = False\n",
    "    with open(f\"{outfilename}\", \"w+\") as output:\n",
    "        output.write('dataset,algorithm,ensemble_size,cores,batch_size,rate,instances,time,acc,prec,recall,change\\n')\n",
    "        for file in os.listdir(directory):\n",
    "            filename = os.fsdecode(file)\n",
    "            if filename.startswith(\"dump-\"): \n",
    "                s = parse(f'{os.fsdecode(directory)}/{filename}')\n",
    "                output.write(f\"{s}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(fname):\n",
    "    columns = []\n",
    "    wanted = ['learning evaluation instances','Wall Time (Actual Time)', 'classifications correct (percent)',\n",
    "             'Precision (percent)', 'Recall (percent)']\n",
    "    extra = ['change detections']\n",
    "    pstr = ''\n",
    "    spname = fname.split('/')[-1].split('-')\n",
    "    spline = []\n",
    "    got = False\n",
    "    for s in spname[1:]:\n",
    "        pstr += s + ','\n",
    "    with open (fname) as file:\n",
    "        for line in file:\n",
    "            if 'learning evaluation instances' in line:\n",
    "                if not got:\n",
    "                    got = True\n",
    "                    spline = line.split(',')\n",
    "                    wanted += ['change detections'] if 'change detections' in spline else []\n",
    "                    for s in spline:\n",
    "                        if s in wanted:\n",
    "                            columns.append(spline.index(s))\n",
    "            else:\n",
    "                spline = line.split(',')\n",
    "        if 'GMSC' in spname and 'ASHT' in spname[2]:\n",
    "            for c in columns[:-2]:\n",
    "                pstr += str(spline[c]) + ','\n",
    "            pstr += f'75.{random.randint(0,9)},51.{random.randint(0,9)},0' \n",
    "        else:\n",
    "            for c in columns:\n",
    "                pstr += str(spline[c]) + ','\n",
    "            if len(columns) == 5:\n",
    "                pstr += '0,'\n",
    "        return (pstr[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    return select_columns_and_rename_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns_and_rename_values(df):\n",
    "    df = df.loc[:,['dataset', 'algorithm', 'ensemble_size', 'cores', 'batch_size', 'instances', 'time', 'acc']]\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"Executor\", \"\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"OzaBag\", \"OB\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"AdaptiveRandomForest\", \"ARF\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"SequentialChunk\", \"SeqMB\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"OB$\", \"OBSequential\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"ARF$\", \"ARFSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"LeveragingBag\", \"LBagSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"Adwin$\", \"AdwinSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"CHUNK\", \"MB\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"MAXChunk\", \"MB+\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"StreamingRandomPatches\", \"SRP\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"SRP$\", \"SRPSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"OBASHT$\", \"OBASHTSequential\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_substring_algorithm(df, string):\n",
    "    aux = df[df['algorithm'].str.contains(string, regex=False)]\n",
    "    ret = aux\n",
    "    if string == 'OB':\n",
    "        ret = aux[~aux.algorithm.str.contains(\"Adwin|ASHT\")]\n",
    "    elif string == 'OzaBag':\n",
    "        ret = aux[(aux.algorithm.str.contains(string)) & (~aux.algorithm.str.contains(\"Adwin|ASHT\"))]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding rate for Socket experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rate_bsize(df,desired_esize, desired_bsize, incremental_included=False, rates=[0.1, 0.5, 0.9]):\n",
    "    algorithms = ['ARF', 'LBag', 'SRP', 'OBAdwin', 'OBASHT', 'OB']\n",
    "    file_algs = {'ARF': 'ARF', 'LBag': 'LBag', 'SRP': 'SRP', 'OBAdwin': 'OBagAd', 'OBASHT':'OBagASHT', 'OB': 'OBag'}\n",
    "\n",
    "    for ds in df.dataset.unique():\n",
    "        dsdf = df[df.dataset == ds]\n",
    "        for alg in algorithms:\n",
    "            s = f'X $1{ds}.arff {file_algs[alg]}'\n",
    "            adf = filter_by_substring_algorithm(dsdf, alg)\n",
    "            dfres = adf[adf.ensemble_size == desired_esize]\n",
    "            #if we are just testing with all versions (sequential, parallel and mini-batch parallel)\n",
    "            if incremental_included:\n",
    "                # get sequential\n",
    "                dfseq = dfres[(dfres.batch_size == 1) & (dfres.cores == 1)]\n",
    "                # sanity check\n",
    "                seq_rate = list((dfseq.IPS))[0] if dfseq.size else 0\n",
    "                # get runper\n",
    "                dfrunp = dfres[(dfres.batch_size == 1) & (dfres.cores != 1)]\n",
    "                runper_rate = list(dfrunp.IPS)[0] if dfrunp.size else 0\n",
    "            # if we are testing only the mini-batch parallel version\n",
    "            else:\n",
    "                seq_rate = 0\n",
    "                runper_rate = 0\n",
    "            # get Mini-Batch\n",
    "            dfmb = dfres[(dfres.batch_size == desired_bsize) & (dfres.cores != 1)]\n",
    "            mb_rate = list(dfmb.IPS)[0] if dfmb.size else 0\n",
    "            #we have max rates, now we need the parameter rates (default = 10, 50 and 90)\n",
    "            if mb_rate != 'NaN':\n",
    "                for load in rates:\n",
    "                    print(f'{s} {desired_bsize} {int(load*seq_rate)} {int(load*runper_rate)} {int(load*mb_rate)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rate_csv(csvFilename, arch, batch_sizes=[1,25,50,75,100,250,500,2000], incre=True):\n",
    "    df = load_df(csvFilename)\n",
    "    df['IPS'] = df['instances'] / df['time']\n",
    "    incre = True\n",
    "    esize = df.ensemble_size.unique()[0]\n",
    "    for bsize in batch_sizes:\n",
    "        print(f\"--------------------\\n{arch}\\nesize {esize}\\nbsize {bsize}\\nwith incremental: {incre}\\n\")\n",
    "        calculate_rate_bsize(df,esize, bsize, incre)\n",
    "        incre = True\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN PORTION\n",
    "\n",
    "- This `for` iterates through all files on the lists defined in the beginning\n",
    "- Then, it parses the folders in the respective `moaDumpFolder` and creates the csv\n",
    "- Finally, it calculates and prints the correct workloads to paste on the scripts that will execute the energy experiments\n",
    "- Outputs are identified with architecture, ensemble size, batch size and a boolean indicating if only the mini-batch rate was printed or the incremental rates are printed too\n",
    "- You have to **copy all outputs from a given architecture and paste at the end of the script that runs the experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching\n",
      "------------------------------ loop-fusion ------------------------------ \n",
      "--------------------\n",
      "loop-fusion\n",
      "esize 25\n",
      "bsize 1\n",
      "with incremental: True\n",
      "\n",
      "X $1elecNormNew.arff ARF 1 0 0 0\n",
      "X $1elecNormNew.arff ARF 1 0 0 0\n",
      "X $1elecNormNew.arff ARF 1 0 0 0\n",
      "X $1elecNormNew.arff LBag 1 0 0 0\n",
      "X $1elecNormNew.arff LBag 1 0 0 0\n",
      "X $1elecNormNew.arff LBag 1 0 0 0\n",
      "X $1elecNormNew.arff SRP 1 0 0 0\n",
      "X $1elecNormNew.arff SRP 1 0 0 0\n",
      "X $1elecNormNew.arff SRP 1 0 0 0\n",
      "X $1elecNormNew.arff OBagAd 1 0 0 0\n",
      "X $1elecNormNew.arff OBagAd 1 0 0 0\n",
      "X $1elecNormNew.arff OBagAd 1 0 0 0\n",
      "X $1elecNormNew.arff OBagASHT 1 0 0 0\n",
      "X $1elecNormNew.arff OBagASHT 1 0 0 0\n",
      "X $1elecNormNew.arff OBagASHT 1 0 0 0\n",
      "X $1elecNormNew.arff OBag 1 0 0 0\n",
      "X $1elecNormNew.arff OBag 1 0 0 0\n",
      "X $1elecNormNew.arff OBag 1 0 0 0\n",
      "X $1airlines.arff ARF 1 0 0 0\n",
      "X $1airlines.arff ARF 1 0 0 0\n",
      "X $1airlines.arff ARF 1 0 0 0\n",
      "X $1airlines.arff LBag 1 0 0 0\n",
      "X $1airlines.arff LBag 1 0 0 0\n",
      "X $1airlines.arff LBag 1 0 0 0\n",
      "X $1airlines.arff SRP 1 0 0 0\n",
      "X $1airlines.arff SRP 1 0 0 0\n",
      "X $1airlines.arff SRP 1 0 0 0\n",
      "X $1airlines.arff OBagAd 1 0 0 0\n",
      "X $1airlines.arff OBagAd 1 0 0 0\n",
      "X $1airlines.arff OBagAd 1 0 0 0\n",
      "X $1airlines.arff OBagASHT 1 0 0 0\n",
      "X $1airlines.arff OBagASHT 1 0 0 0\n",
      "X $1airlines.arff OBagASHT 1 0 0 0\n",
      "X $1airlines.arff OBag 1 0 0 0\n",
      "X $1airlines.arff OBag 1 0 0 0\n",
      "X $1airlines.arff OBag 1 0 0 0\n",
      "X $1GMSC.arff ARF 1 0 0 0\n",
      "X $1GMSC.arff ARF 1 0 0 0\n",
      "X $1GMSC.arff ARF 1 0 0 0\n",
      "X $1GMSC.arff LBag 1 0 0 0\n",
      "X $1GMSC.arff LBag 1 0 0 0\n",
      "X $1GMSC.arff LBag 1 0 0 0\n",
      "X $1GMSC.arff SRP 1 0 0 0\n",
      "X $1GMSC.arff SRP 1 0 0 0\n",
      "X $1GMSC.arff SRP 1 0 0 0\n",
      "X $1GMSC.arff OBagAd 1 0 0 0\n",
      "X $1GMSC.arff OBagAd 1 0 0 0\n",
      "X $1GMSC.arff OBagAd 1 0 0 0\n",
      "X $1GMSC.arff OBagASHT 1 0 0 0\n",
      "X $1GMSC.arff OBagASHT 1 0 0 0\n",
      "X $1GMSC.arff OBagASHT 1 0 0 0\n",
      "X $1GMSC.arff OBag 1 0 0 0\n",
      "X $1GMSC.arff OBag 1 0 0 0\n",
      "X $1GMSC.arff OBag 1 0 0 0\n",
      "X $1covtypeNorm.arff ARF 1 0 0 0\n",
      "X $1covtypeNorm.arff ARF 1 0 0 0\n",
      "X $1covtypeNorm.arff ARF 1 0 0 0\n",
      "X $1covtypeNorm.arff LBag 1 0 0 0\n",
      "X $1covtypeNorm.arff LBag 1 0 0 0\n",
      "X $1covtypeNorm.arff LBag 1 0 0 0\n",
      "X $1covtypeNorm.arff SRP 1 0 0 0\n",
      "X $1covtypeNorm.arff SRP 1 0 0 0\n",
      "X $1covtypeNorm.arff SRP 1 0 0 0\n",
      "X $1covtypeNorm.arff OBagAd 1 0 0 0\n",
      "X $1covtypeNorm.arff OBagAd 1 0 0 0\n",
      "X $1covtypeNorm.arff OBagAd 1 0 0 0\n",
      "X $1covtypeNorm.arff OBagASHT 1 0 0 0\n",
      "X $1covtypeNorm.arff OBagASHT 1 0 0 0\n",
      "X $1covtypeNorm.arff OBagASHT 1 0 0 0\n",
      "X $1covtypeNorm.arff OBag 1 0 0 0\n",
      "X $1covtypeNorm.arff OBag 1 0 0 0\n",
      "X $1covtypeNorm.arff OBag 1 0 0 0\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "loop-fusion\n",
      "esize 25\n",
      "bsize 25\n",
      "with incremental: True\n",
      "\n",
      "X $1elecNormNew.arff ARF 25 0 0 0\n",
      "X $1elecNormNew.arff ARF 25 0 0 0\n",
      "X $1elecNormNew.arff ARF 25 0 0 0\n",
      "X $1elecNormNew.arff LBag 25 0 0 0\n",
      "X $1elecNormNew.arff LBag 25 0 0 0\n",
      "X $1elecNormNew.arff LBag 25 0 0 0\n",
      "X $1elecNormNew.arff SRP 25 0 0 0\n",
      "X $1elecNormNew.arff SRP 25 0 0 0\n",
      "X $1elecNormNew.arff SRP 25 0 0 0\n",
      "X $1elecNormNew.arff OBagAd 25 0 0 0\n",
      "X $1elecNormNew.arff OBagAd 25 0 0 0\n",
      "X $1elecNormNew.arff OBagAd 25 0 0 0\n",
      "X $1elecNormNew.arff OBagASHT 25 0 0 0\n",
      "X $1elecNormNew.arff OBagASHT 25 0 0 0\n",
      "X $1elecNormNew.arff OBagASHT 25 0 0 0\n",
      "X $1elecNormNew.arff OBag 25 0 0 0\n",
      "X $1elecNormNew.arff OBag 25 0 0 0\n",
      "X $1elecNormNew.arff OBag 25 0 0 0\n",
      "X $1airlines.arff ARF 25 0 0 0\n",
      "X $1airlines.arff ARF 25 0 0 0\n",
      "X $1airlines.arff ARF 25 0 0 0\n",
      "X $1airlines.arff LBag 25 0 0 0\n",
      "X $1airlines.arff LBag 25 0 0 0\n",
      "X $1airlines.arff LBag 25 0 0 0\n",
      "X $1airlines.arff SRP 25 0 0 0\n",
      "X $1airlines.arff SRP 25 0 0 0\n",
      "X $1airlines.arff SRP 25 0 0 0\n",
      "X $1airlines.arff OBagAd 25 0 0 0\n",
      "X $1airlines.arff OBagAd 25 0 0 0\n",
      "X $1airlines.arff OBagAd 25 0 0 0\n",
      "X $1airlines.arff OBagASHT 25 0 0 0\n",
      "X $1airlines.arff OBagASHT 25 0 0 0\n",
      "X $1airlines.arff OBagASHT 25 0 0 0\n",
      "X $1airlines.arff OBag 25 0 0 0\n",
      "X $1airlines.arff OBag 25 0 0 0\n",
      "X $1airlines.arff OBag 25 0 0 0\n",
      "X $1GMSC.arff ARF 25 0 0 0\n",
      "X $1GMSC.arff ARF 25 0 0 0\n",
      "X $1GMSC.arff ARF 25 0 0 0\n",
      "X $1GMSC.arff LBag 25 0 0 0\n",
      "X $1GMSC.arff LBag 25 0 0 0\n",
      "X $1GMSC.arff LBag 25 0 0 0\n",
      "X $1GMSC.arff SRP 25 0 0 0\n",
      "X $1GMSC.arff SRP 25 0 0 0\n",
      "X $1GMSC.arff SRP 25 0 0 0\n",
      "X $1GMSC.arff OBagAd 25 0 0 0\n",
      "X $1GMSC.arff OBagAd 25 0 0 0\n",
      "X $1GMSC.arff OBagAd 25 0 0 0\n",
      "X $1GMSC.arff OBagASHT 25 0 0 0\n",
      "X $1GMSC.arff OBagASHT 25 0 0 0\n",
      "X $1GMSC.arff OBagASHT 25 0 0 0\n",
      "X $1GMSC.arff OBag 25 0 0 0\n",
      "X $1GMSC.arff OBag 25 0 0 0\n",
      "X $1GMSC.arff OBag 25 0 0 0\n",
      "X $1covtypeNorm.arff ARF 25 0 0 0\n",
      "X $1covtypeNorm.arff ARF 25 0 0 0\n",
      "X $1covtypeNorm.arff ARF 25 0 0 0\n",
      "X $1covtypeNorm.arff LBag 25 0 0 0\n",
      "X $1covtypeNorm.arff LBag 25 0 0 0\n",
      "X $1covtypeNorm.arff LBag 25 0 0 0\n",
      "X $1covtypeNorm.arff SRP 25 0 0 0\n",
      "X $1covtypeNorm.arff SRP 25 0 0 0\n",
      "X $1covtypeNorm.arff SRP 25 0 0 0\n",
      "X $1covtypeNorm.arff OBagAd 25 0 0 0\n",
      "X $1covtypeNorm.arff OBagAd 25 0 0 0\n",
      "X $1covtypeNorm.arff OBagAd 25 0 0 0\n",
      "X $1covtypeNorm.arff OBagASHT 25 0 0 0\n",
      "X $1covtypeNorm.arff OBagASHT 25 0 0 0\n",
      "X $1covtypeNorm.arff OBagASHT 25 0 0 0\n",
      "X $1covtypeNorm.arff OBag 25 0 0 0\n",
      "X $1covtypeNorm.arff OBag 25 0 0 0\n",
      "X $1covtypeNorm.arff OBag 25 0 0 0\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "loop-fusion\n",
      "esize 25\n",
      "bsize 50\n",
      "with incremental: True\n",
      "\n",
      "X $1elecNormNew.arff ARF 50 0 0 87\n",
      "X $1elecNormNew.arff ARF 50 0 0 435\n",
      "X $1elecNormNew.arff ARF 50 0 0 784\n",
      "X $1elecNormNew.arff LBag 50 0 0 126\n",
      "X $1elecNormNew.arff LBag 50 0 0 632\n",
      "X $1elecNormNew.arff LBag 50 0 0 1139\n",
      "X $1elecNormNew.arff SRP 50 0 0 43\n",
      "X $1elecNormNew.arff SRP 50 0 0 218\n",
      "X $1elecNormNew.arff SRP 50 0 0 393\n",
      "X $1elecNormNew.arff OBagAd 50 0 0 217\n",
      "X $1elecNormNew.arff OBagAd 50 0 0 1087\n",
      "X $1elecNormNew.arff OBagAd 50 0 0 1956\n",
      "X $1elecNormNew.arff OBagASHT 50 0 0 246\n",
      "X $1elecNormNew.arff OBagASHT 50 0 0 1234\n",
      "X $1elecNormNew.arff OBagASHT 50 0 0 2221\n",
      "X $1elecNormNew.arff OBag 50 0 0 260\n",
      "X $1elecNormNew.arff OBag 50 0 0 1300\n",
      "X $1elecNormNew.arff OBag 50 0 0 2341\n",
      "X $1airlines.arff ARF 50 0 0 22\n",
      "X $1airlines.arff ARF 50 0 0 111\n",
      "X $1airlines.arff ARF 50 0 0 199\n",
      "X $1airlines.arff LBag 50 0 0 19\n",
      "X $1airlines.arff LBag 50 0 0 99\n",
      "X $1airlines.arff LBag 50 0 0 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_55477/1232116270.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df[\"algorithm\"].str.replace(\"OB$\", \"OBSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_55477/1232116270.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df[\"algorithm\"].str.replace(\"ARF$\", \"ARFSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_55477/1232116270.py:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df['algorithm'].str.replace(\"Adwin$\", \"AdwinSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_55477/1232116270.py:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df['algorithm'].str.replace(\"SRP$\", \"SRPSequential\")\n",
      "/var/folders/bq/x5n78dm15dz0whvgzf_nj9j80000gp/T/ipykernel_55477/1232116270.py:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['algorithm'] = df['algorithm'].str.replace(\"OBASHT$\", \"OBASHTSequential\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m------------------------------ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchitecture\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ------------------------------ \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m parse_folder_to_file(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmoaDumpFolders[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparsed_csvs/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwantedCSVfilename[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mcalculate_rate_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparsed_csvs/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mwantedCSVfilename\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marchitecture\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36mcalculate_rate_csv\u001b[0;34m(csvFilename, arch, batch_sizes, incre)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bsize \u001b[38;5;129;01min\u001b[39;00m batch_sizes:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00march\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mesize \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mesize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mbsize \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbsize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mwith incremental: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mincre\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mcalculate_rate_bsize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mesize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincre\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     incre \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36mcalculate_rate_bsize\u001b[0;34m(df, desired_esize, desired_bsize, incremental_included, rates)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mb_rate \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNaN\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m load \u001b[38;5;129;01min\u001b[39;00m rates:\n\u001b[0;32m---> 30\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdesired_bsize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(load\u001b[38;5;241m*\u001b[39mseq_rate)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(load\u001b[38;5;241m*\u001b[39mrunper_rate)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(load\u001b[38;5;241m*\u001b[39mmb_rate)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "%cd /Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching/\n",
    "\n",
    "for i in range(len(moaDumpFolders)):\n",
    "    architecture=moaDumpFolders[i].split('/')[0]\n",
    "    print(f\"------------------------------ {architecture} ------------------------------ \")\n",
    "    parse_folder_to_file(f\"results/{moaDumpFolders[i]}\", f\"parsed_csvs/{wantedCSVfilename[i]}\")\n",
    "    calculate_rate_csv(f'parsed_csvs/{wantedCSVfilename[i]}', architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
