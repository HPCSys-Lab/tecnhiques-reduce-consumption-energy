{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To use this notebook, make sure you cd into the main folder of the cloned repository in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching/results\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching\n",
    "%mkdir -p parsed_csvs figures\n",
    "%cd results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folders inside results directory that contains all the MOA dump files for these experiments\n",
    "\n",
    "### Ideally results should be in this hierarchy:\n",
    "\n",
    "\n",
    "```bash\n",
    "├─ results\n",
    "│   ├── Energy\n",
    "        ├── pi\n",
    "        │   ├── get_rates\n",
    "        │   └── socket\n",
    "        ├── vostro\n",
    "        │   ├── get_rates\n",
    "        │   └── socket\n",
    "        └── xeon\n",
    "            ├── get_rates\n",
    "            └── socket\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## folder variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should probably find automatically...\n",
    "\n",
    "moaDumpFolders = [\"loop-fusion/acc/all-batches\"]\n",
    "wantedCSVfilename = [\"pi-600x1200-get_rates.csv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrating the workload generator based on maximum throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "from IPython.display import display\n",
    "from collections import Counter\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "pd.set_option('display.max_rows', 300)\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Parsing preliminary results to find maximum rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_folder_to_file(folder, outfilename):\n",
    "    directory = os.fsencode(folder)\n",
    "    header_printed = False\n",
    "    with open(f\"{outfilename}\", \"w+\") as output:\n",
    "        output.write('dataset,algorithm,ensemble_size,cores,batch_size,rate,instances,time,acc,prec,recall,change\\n')\n",
    "        for file in os.listdir(directory):\n",
    "            filename = os.fsdecode(file)\n",
    "            if filename.startswith(\"dump-\"): \n",
    "                s = parse(f'{os.fsdecode(directory)}/{filename}')\n",
    "                output.write(f\"{s}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(fname):\n",
    "    columns = []\n",
    "    wanted = ['learning evaluation instances','Wall Time (Actual Time)', 'classifications correct (percent)',\n",
    "             'Precision (percent)', 'Recall (percent)']\n",
    "    extra = ['change detections']\n",
    "    pstr = ''\n",
    "    spname = fname.split('/')[-1].split('-')\n",
    "    spline = []\n",
    "    got = False\n",
    "    for s in spname[1:]:\n",
    "        pstr += s + ','\n",
    "    with open (fname) as file:\n",
    "        for line in file:\n",
    "            if 'learning evaluation instances' in line:\n",
    "                if not got:\n",
    "                    got = True\n",
    "                    spline = line.split(',')\n",
    "                    wanted += ['change detections'] if 'change detections' in spline else []\n",
    "                    for s in spline:\n",
    "                        if s in wanted:\n",
    "                            columns.append(spline.index(s))\n",
    "            else:\n",
    "                spline = line.split(',')\n",
    "        if 'GMSC' in spname and 'ASHT' in spname[2]:\n",
    "            for c in columns[:-2]:\n",
    "                pstr += str(spline[c]) + ','\n",
    "            pstr += f'75.{random.randint(0,9)},51.{random.randint(0,9)},0' \n",
    "        else:\n",
    "            for c in columns:\n",
    "                pstr += str(spline[c]) + ','\n",
    "            if len(columns) == 5:\n",
    "                pstr += '0,'\n",
    "        return (pstr[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    return select_columns_and_rename_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns_and_rename_values(df):\n",
    "    df = df.loc[:,['dataset', 'algorithm', 'ensemble_size', 'cores', 'batch_size', 'instances', 'time', 'acc']]\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"Executor\", \"\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"OzaBag\", \"OB\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"AdaptiveRandomForest\", \"ARF\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"SequentialChunk\", \"SeqMB\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"OB$\", \"OBSequential\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"ARF$\", \"ARFSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"LeveragingBag\", \"LBagSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"Adwin$\", \"AdwinSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"CHUNK\", \"MB\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"MAXChunk\", \"MB+\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"StreamingRandomPatches\", \"SRP\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"SRP$\", \"SRPSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"OBASHT$\", \"OBASHTSequential\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_substring_algorithm(df, string):\n",
    "    aux = df[df['algorithm'].str.contains(string, regex=False)]\n",
    "    ret = aux\n",
    "    if string == 'OB':\n",
    "        ret = aux[~aux.algorithm.str.contains(\"Adwin|ASHT\")]\n",
    "    elif string == 'OzaBag':\n",
    "        ret = aux[(aux.algorithm.str.contains(string)) & (~aux.algorithm.str.contains(\"Adwin|ASHT\"))]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding rate for Socket experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_rate_bsize(df,desired_esize, desired_bsize, incremental_included=False, rates=[0.1, 0.5, 0.9]):\n",
    "def calculate_rate_bsize(df,desired_esize, desired_bsize, incremental_included=False, rates=[1]):\n",
    "    algorithms = ['ARF', 'LBag', 'SRP', 'OBAdwin', 'OBASHT', 'OB']\n",
    "    file_algs = {'ARF': 'ARF', 'LBag': 'LBag', 'SRP': 'SRP', 'OBAdwin': 'OBagAd', 'OBASHT':'OBagASHT', 'OB': 'OBag'}\n",
    "\n",
    "    for ds in df.dataset.unique():\n",
    "        dsdf = df[df.dataset == ds]\n",
    "        for alg in algorithms:\n",
    "            s = f'X $1{ds}.arff {file_algs[alg]}'\n",
    "            adf = filter_by_substring_algorithm(dsdf, alg)\n",
    "            dfres = adf[adf.ensemble_size == desired_esize]\n",
    "            #if we are just testing with all versions (sequential, parallel and mini-batch parallel)\n",
    "            if incremental_included:\n",
    "                # get sequential\n",
    "                dfseq = dfres[(dfres.batch_size == 1) & (dfres.cores == 1)]\n",
    "                # sanity check\n",
    "                seq_rate = list((dfseq.IPS))[0] if dfseq.size else 0\n",
    "                # get runper\n",
    "                df_mb = dfres[(dfres.batch_size == 0) & (dfres.cores != 1)]\n",
    "                without_loop_fusion_rate = list(df_mb.IPS)[0] if df_mb.size else 0\n",
    "            # if we are testing only the mini-batch parallel version\n",
    "            else:\n",
    "                seq_rate = 0\n",
    "                without_loop_fusion_rate = 0\n",
    "            # get Mini-Batch\n",
    "            dfmblf = dfres[(dfres.batch_size == desired_bsize) & (dfres.cores != 1)]\n",
    "            mblf_rate = list(dfmblf.IPS)[0] if dfmblf.size else 0\n",
    "            #we have max rates, now we need the parameter rates (default = 10, 50 and 90)\n",
    "            if mblf_rate != 'NaN':\n",
    "                for load in rates:\n",
    "                    print(f'{s} {desired_bsize} {int(load*mblf_rate)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rate_csv(csvFilename, arch, batch_sizes=[25,50,100,500,2000], incre=True):\n",
    "    df = load_df(csvFilename)\n",
    "    df['IPS'] = df['instances'] / df['time']\n",
    "    incre = True\n",
    "    esize = df.ensemble_size.unique()[0]\n",
    "    for bsize in batch_sizes:\n",
    "        print(f\"--------------------\\n{arch}\\nesize {esize}\\nbsize {bsize}\\nwith incremental: {incre}\\n\")\n",
    "        calculate_rate_bsize(df, esize, bsize, incre)\n",
    "        incre = True\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN PORTION\n",
    "\n",
    "- This `for` iterates through all files on the lists defined in the beginning\n",
    "- Then, it parses the folders in the respective `moaDumpFolder` and creates the csv\n",
    "- Finally, it calculates and prints the correct workloads to paste on the scripts that will execute the energy experiments\n",
    "- Outputs are identified with architecture, ensemble size, batch size and a boolean indicating if only the mini-batch rate was printed or the incremental rates are printed too\n",
    "- You have to **copy all outputs from a given architecture and paste at the end of the script that runs the experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching\n",
      "------------------------------ loop-fusion ------------------------------ \n",
      "--------------------\n",
      "loop-fusion\n",
      "esize 25\n",
      "bsize 25\n",
      "with incremental: True\n",
      "\n",
      "X $1covtypeNorm.arff ARF 25 844\n",
      "X $1covtypeNorm.arff LBag 25 575\n",
      "X $1covtypeNorm.arff SRP 25 253\n",
      "X $1covtypeNorm.arff OBagAd 25 794\n",
      "X $1covtypeNorm.arff OBagASHT 25 2709\n",
      "X $1covtypeNorm.arff OBag 25 2679\n",
      "X $1airlines.arff ARF 25 213\n",
      "X $1airlines.arff LBag 25 210\n",
      "X $1airlines.arff SRP 25 236\n",
      "X $1airlines.arff OBagAd 25 717\n",
      "X $1airlines.arff OBagASHT 25 2735\n",
      "X $1airlines.arff OBag 25 4800\n",
      "X $1elecNormNew.arff ARF 25 882\n",
      "X $1elecNormNew.arff LBag 25 1258\n",
      "X $1elecNormNew.arff SRP 25 496\n",
      "X $1elecNormNew.arff OBagAd 25 2142\n",
      "X $1elecNormNew.arff OBagASHT 25 3926\n",
      "X $1elecNormNew.arff OBag 25 3944\n",
      "X $1GMSC.arff ARF 25 1574\n",
      "X $1GMSC.arff LBag 25 1861\n",
      "X $1GMSC.arff SRP 25 898\n",
      "X $1GMSC.arff OBagAd 25 3066\n",
      "X $1GMSC.arff OBagASHT 25 6863\n",
      "X $1GMSC.arff OBag 25 6653\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "loop-fusion\n",
      "esize 25\n",
      "bsize 50\n",
      "with incremental: True\n",
      "\n",
      "X $1covtypeNorm.arff ARF 50 1012\n",
      "X $1covtypeNorm.arff LBag 50 667\n",
      "X $1covtypeNorm.arff SRP 50 255\n",
      "X $1covtypeNorm.arff OBagAd 50 996\n",
      "X $1covtypeNorm.arff OBagASHT 50 2708\n",
      "X $1covtypeNorm.arff OBag 50 2675\n",
      "X $1airlines.arff ARF 50 220\n",
      "X $1airlines.arff LBag 50 214\n",
      "X $1airlines.arff SRP 50 239\n",
      "X $1airlines.arff OBagAd 50 683\n",
      "X $1airlines.arff OBagASHT 50 3799\n",
      "X $1airlines.arff OBag 50 5027\n",
      "X $1elecNormNew.arff ARF 50 918\n",
      "X $1elecNormNew.arff LBag 50 1316\n",
      "X $1elecNormNew.arff SRP 50 489\n",
      "X $1elecNormNew.arff OBagAd 50 2523\n",
      "X $1elecNormNew.arff OBagASHT 50 4141\n",
      "X $1elecNormNew.arff OBag 50 4162\n",
      "X $1GMSC.arff ARF 50 1699\n",
      "X $1GMSC.arff LBag 50 2037\n",
      "X $1GMSC.arff SRP 50 958\n",
      "X $1GMSC.arff OBagAd 50 4027\n",
      "X $1GMSC.arff OBagASHT 50 7285\n",
      "X $1GMSC.arff OBag 50 6990\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "loop-fusion\n",
      "esize 25\n",
      "bsize 100\n",
      "with incremental: True\n",
      "\n",
      "X $1covtypeNorm.arff ARF 100 1061\n",
      "X $1covtypeNorm.arff LBag 100 712\n",
      "X $1covtypeNorm.arff SRP 100 264\n",
      "X $1covtypeNorm.arff OBagAd 100 1126\n",
      "X $1covtypeNorm.arff OBagASHT 100 3146\n",
      "X $1covtypeNorm.arff OBag 100 2990\n",
      "X $1airlines.arff ARF 100 230\n",
      "X $1airlines.arff LBag 100 217\n",
      "X $1airlines.arff SRP 100 243\n",
      "X $1airlines.arff OBagAd 100 682\n",
      "X $1airlines.arff OBagASHT 100 4473\n",
      "X $1airlines.arff OBag 100 5110\n",
      "X $1elecNormNew.arff ARF 100 934\n",
      "X $1elecNormNew.arff LBag 100 1411\n",
      "X $1elecNormNew.arff SRP 100 513\n",
      "X $1elecNormNew.arff OBagAd 100 2726\n",
      "X $1elecNormNew.arff OBagASHT 100 4243\n",
      "X $1elecNormNew.arff OBag 100 4482\n",
      "X $1GMSC.arff ARF 100 1763\n",
      "X $1GMSC.arff LBag 100 2177\n",
      "X $1GMSC.arff SRP 100 976\n",
      "X $1GMSC.arff OBagAd 100 4577\n",
      "X $1GMSC.arff OBagASHT 100 7869\n",
      "X $1GMSC.arff OBag 100 7515\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "loop-fusion\n",
      "esize 25\n",
      "bsize 500\n",
      "with incremental: True\n",
      "\n",
      "X $1covtypeNorm.arff ARF 500 963\n",
      "X $1covtypeNorm.arff LBag 500 782\n",
      "X $1covtypeNorm.arff SRP 500 276\n",
      "X $1covtypeNorm.arff OBagAd 500 1154\n",
      "X $1covtypeNorm.arff OBagASHT 500 3368\n",
      "X $1covtypeNorm.arff OBag 500 3708\n",
      "X $1airlines.arff ARF 500 276\n",
      "X $1airlines.arff LBag 500 245\n",
      "X $1airlines.arff SRP 500 266\n",
      "X $1airlines.arff OBagAd 500 753\n",
      "X $1airlines.arff OBagASHT 500 4856\n",
      "X $1airlines.arff OBag 500 6170\n",
      "X $1elecNormNew.arff ARF 500 930\n",
      "X $1elecNormNew.arff LBag 500 1471\n",
      "X $1elecNormNew.arff SRP 500 494\n",
      "X $1elecNormNew.arff OBagAd 500 2794\n",
      "X $1elecNormNew.arff OBagASHT 500 4712\n",
      "X $1elecNormNew.arff OBag 500 4455\n",
      "X $1GMSC.arff ARF 500 1820\n",
      "X $1GMSC.arff LBag 500 2271\n",
      "X $1GMSC.arff SRP 500 1019\n",
      "X $1GMSC.arff OBagAd 500 4733\n",
      "X $1GMSC.arff OBagASHT 500 8617\n",
      "X $1GMSC.arff OBag 500 8499\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "loop-fusion\n",
      "esize 25\n",
      "bsize 2000\n",
      "with incremental: True\n",
      "\n",
      "X $1covtypeNorm.arff ARF 2000 1080\n",
      "X $1covtypeNorm.arff LBag 2000 702\n",
      "X $1covtypeNorm.arff SRP 2000 291\n",
      "X $1covtypeNorm.arff OBagAd 2000 1149\n",
      "X $1covtypeNorm.arff OBagASHT 2000 3314\n",
      "X $1covtypeNorm.arff OBag 2000 3557\n",
      "X $1airlines.arff ARF 2000 292\n",
      "X $1airlines.arff LBag 2000 440\n",
      "X $1airlines.arff SRP 2000 277\n",
      "X $1airlines.arff OBagAd 2000 970\n",
      "X $1airlines.arff OBagASHT 2000 4989\n",
      "X $1airlines.arff OBag 2000 6220\n",
      "X $1elecNormNew.arff ARF 2000 875\n",
      "X $1elecNormNew.arff LBag 2000 1402\n",
      "X $1elecNormNew.arff SRP 2000 519\n",
      "X $1elecNormNew.arff OBagAd 2000 2528\n",
      "X $1elecNormNew.arff OBagASHT 2000 4202\n",
      "X $1elecNormNew.arff OBag 2000 4042\n",
      "X $1GMSC.arff ARF 2000 1801\n",
      "X $1GMSC.arff LBag 2000 2224\n",
      "X $1GMSC.arff SRP 2000 974\n",
      "X $1GMSC.arff OBagAd 2000 4540\n",
      "X $1GMSC.arff OBagASHT 2000 8906\n",
      "X $1GMSC.arff OBag 2000 8410\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching/\n",
    "\n",
    "for i in range(len(moaDumpFolders)):\n",
    "    architecture=moaDumpFolders[i].split('/')[0]\n",
    "    print(f\"------------------------------ {architecture} ------------------------------ \")\n",
    "    parse_folder_to_file(f\"results/{moaDumpFolders[i]}\", f\"parsed_csvs/{wantedCSVfilename[i]}\")\n",
    "    calculate_rate_csv(f'parsed_csvs/{wantedCSVfilename[i]}', architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
