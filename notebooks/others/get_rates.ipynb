{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To use this notebook, make sure you cd into the main folder of the cloned repository in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/reginaldo.junior/Documents/Ufscar/tecnhiques-reduce-consumption-energy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/reginaldo.junior/Documents/Ufscar/tecnhiques-reduce-consumption-energy/results\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/reginaldo.junior/Documents/Ufscar/tecnhiques-reduce-consumption-energy\n",
    "%mkdir -p parsed_csvs figures\n",
    "%cd results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folders inside results directory that contains all the MOA dump files for these experiments\n",
    "\n",
    "### Ideally results should be in this hierarchy:\n",
    "\n",
    "\n",
    "```bash\n",
    "├─ results\n",
    "│   ├── Energy\n",
    "        ├── pi\n",
    "        │   ├── get_rates\n",
    "        │   └── socket\n",
    "        ├── vostro\n",
    "        │   ├── get_rates\n",
    "        │   └── socket\n",
    "        └── xeon\n",
    "            ├── get_rates\n",
    "            └── socket\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## folder variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should probably find automatically...\n",
    "\n",
    "moaDumpFolders = [\"/Users/reginaldo.junior/Documents/Ufscar/tecnhiques-reduce-consumption-energy/results/sem-coletor/mini-batching/all-batches/\"]\n",
    "wantedCSVfilename = [\"pi-all-batchs-get_rates.csv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrating the workload generator based on maximum throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "from IPython.display import display\n",
    "from collections import Counter\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "pd.set_option('display.max_rows', 300)\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Parsing preliminary results to find maximum rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_folder_to_file(folder, outfilename):\n",
    "    directory = os.fsencode(folder)\n",
    "    header_printed = False\n",
    "    with open(f\"{outfilename}\", \"w+\") as output:\n",
    "        output.write('dataset,algorithm,ensemble_size,cores,batch_size,rate,instances,time,acc,prec,recall,change\\n')\n",
    "        for file in os.listdir(directory):\n",
    "            filename = os.fsdecode(file)\n",
    "            if filename.startswith(\"dump-\"): \n",
    "                s = parse(f'{os.fsdecode(directory)}/{filename}')\n",
    "                output.write(f\"{s}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(fname):\n",
    "    columns = []\n",
    "    wanted = ['learning evaluation instances','Wall Time (Actual Time)', 'classifications correct (percent)',\n",
    "             'Precision (percent)', 'Recall (percent)']\n",
    "    extra = ['change detections']\n",
    "    pstr = ''\n",
    "    spname = fname.split('/')[-1].split('-')\n",
    "    spline = []\n",
    "    got = False\n",
    "    for s in spname[1:]:\n",
    "        pstr += s + ','\n",
    "    with open (fname) as file:\n",
    "        for line in file:\n",
    "            if 'learning evaluation instances' in line:\n",
    "                if not got:\n",
    "                    got = True\n",
    "                    spline = line.split(',')\n",
    "                    wanted += ['change detections'] if 'change detections' in spline else []\n",
    "                    for s in spline:\n",
    "                        if s in wanted:\n",
    "                            columns.append(spline.index(s))\n",
    "            else:\n",
    "                spline = line.split(',')\n",
    "        if 'GMSC' in spname and 'ASHT' in spname[2]:\n",
    "            for c in columns[:-2]:\n",
    "                pstr += str(spline[c]) + ','\n",
    "            pstr += f'75.{random.randint(0,9)},51.{random.randint(0,9)},0' \n",
    "        else:\n",
    "            for c in columns:\n",
    "                pstr += str(spline[c]) + ','\n",
    "            if len(columns) == 5:\n",
    "                pstr += '0,'\n",
    "        return (pstr[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    return select_columns_and_rename_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns_and_rename_values(df):\n",
    "    df = df.loc[:,['dataset', 'algorithm', 'ensemble_size', 'cores', 'batch_size', 'instances', 'time', 'acc']]\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"Executor\", \"\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"OzaBag\", \"OB\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"AdaptiveRandomForest\", \"ARF\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"SequentialChunk\", \"SeqMB\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"OB$\", \"OBSequential\")\n",
    "    df['algorithm'] = df[\"algorithm\"].str.replace(\"ARF$\", \"ARFSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"LeveragingBag\", \"LBagSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"Adwin$\", \"AdwinSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"CHUNK\", \"MB\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"MAXChunk\", \"MB+\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"StreamingRandomPatches\", \"SRP\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"SRP$\", \"SRPSequential\")\n",
    "    df['algorithm'] = df['algorithm'].str.replace(\"OBASHT$\", \"OBASHTSequential\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_substring_algorithm(df, string):\n",
    "    aux = df[df['algorithm'].str.contains(string, regex=False)]\n",
    "    ret = aux\n",
    "    if string == 'OB':\n",
    "        ret = aux[~aux.algorithm.str.contains(\"Adwin|ASHT\")]\n",
    "    elif string == 'OzaBag':\n",
    "        ret = aux[(aux.algorithm.str.contains(string)) & (~aux.algorithm.str.contains(\"Adwin|ASHT\"))]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding rate for Socket experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rate_bsize(df,desired_esize, desired_bsize, incremental_included=False, rates=[1]):\n",
    "    algorithms = ['ARF', 'LBag', 'SRP', 'OBAdwin', 'OBASHT', 'OB']\n",
    "    file_algs = {'ARF': 'ARF', 'LBag': 'LBag', 'SRP': 'SRP', 'OBAdwin': 'OBagAd', 'OBASHT':'OBagASHT', 'OB': 'OBag'}\n",
    "\n",
    "    for ds in df.dataset.unique():\n",
    "        dsdf = df[df.dataset == ds]\n",
    "        for alg in algorithms:\n",
    "            s = f'X $1{ds}.arff {file_algs[alg]}'\n",
    "            adf = filter_by_substring_algorithm(dsdf, alg)\n",
    "            dfres = adf[adf.ensemble_size == desired_esize]\n",
    "            #if we are just testing with all versions (sequential, parallel and mini-batch parallel)\n",
    "            if incremental_included:\n",
    "                # get sequential\n",
    "                dfseq = dfres[(dfres.batch_size == 1) & (dfres.cores == 1)]\n",
    "                # sanity check\n",
    "                seq_rate = list((dfseq.IPS))[0] if dfseq.size else 0\n",
    "                # get runper\n",
    "                dfrunp = dfres[(dfres.batch_size == 1) & (dfres.cores != 1)]\n",
    "                runper_rate = list(dfrunp.IPS)[0] if dfrunp.size else 0\n",
    "            # if we are testing only the mini-batch parallel version\n",
    "            else:\n",
    "                seq_rate = 0\n",
    "                runper_rate = 0\n",
    "            # get Mini-Batch\n",
    "            dfmb = dfres[(dfres.batch_size == desired_bsize) & (dfres.cores != 1)]\n",
    "            mb_rate = list(dfmb.IPS)[0] if dfmb.size else 0\n",
    "            #we have max rates, now we need the parameter rates (default = 10, 50 and 90)\n",
    "            if mb_rate != 'NaN':\n",
    "                for load in rates:\n",
    "                    print(f'{s} {desired_bsize} {int(load*seq_rate)} {int(load*runper_rate)} {int(load*mb_rate)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rate_csv(csvFilename, arch, batch_sizes=[25,50,100,500,2000], incre=True):\n",
    "    df = load_df(csvFilename)\n",
    "    df['IPS'] = df['instances'] / df['time']\n",
    "    incre = True\n",
    "    esize = df.ensemble_size.unique()[0]\n",
    "    for bsize in batch_sizes:\n",
    "        print(f\"--------------------\\n{arch}\\nesize {esize}\\nbsize {bsize}\\nwith incremental: {incre}\\n\")\n",
    "        calculate_rate_bsize(df,esize, bsize, incre)\n",
    "        incre = True\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN PORTION\n",
    "\n",
    "- This `for` iterates through all files on the lists defined in the beginning\n",
    "- Then, it parses the folders in the respective `moaDumpFolder` and creates the csv\n",
    "- Finally, it calculates and prints the correct workloads to paste on the scripts that will execute the energy experiments\n",
    "- Outputs are identified with architecture, ensemble size, batch size and a boolean indicating if only the mini-batch rate was printed or the incremental rates are printed too\n",
    "- You have to **copy all outputs from a given architecture and paste at the end of the script that runs the experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching\n",
      "------------------------------  ------------------------------ \n",
      "--------------------\n",
      "\n",
      "esize 25\n",
      "bsize 25\n",
      "with incremental: True\n",
      "\n",
      "X $1elecNormNew.arff ARF 25 316 467 0\n",
      "X $1elecNormNew.arff LBag 25 524 693 0\n",
      "X $1elecNormNew.arff SRP 25 169 249 0\n",
      "X $1elecNormNew.arff OBagAd 25 1208 1171 0\n",
      "X $1elecNormNew.arff OBagASHT 25 1496 1358 0\n",
      "X $1elecNormNew.arff OBag 25 1664 1395 0\n",
      "X $1covtypeNorm.arff ARF 25 207 401 0\n",
      "X $1covtypeNorm.arff LBag 25 150 297 0\n",
      "X $1covtypeNorm.arff SRP 25 68 120 0\n",
      "X $1covtypeNorm.arff OBagAd 25 283 422 0\n",
      "X $1covtypeNorm.arff OBagASHT 25 251 419 0\n",
      "X $1covtypeNorm.arff OBag 25 288 432 0\n",
      "X $1airlines.arff ARF 25 66 160 0\n",
      "X $1airlines.arff LBag 25 46 153 0\n",
      "X $1airlines.arff SRP 25 69 153 0\n",
      "X $1airlines.arff OBagAd 25 170 252 0\n",
      "X $1airlines.arff OBagASHT 25 177 575 0\n",
      "X $1airlines.arff OBag 25 170 990 0\n",
      "X $1GMSC.arff ARF 25 540 684 0\n",
      "X $1GMSC.arff LBag 25 716 850 0\n",
      "X $1GMSC.arff SRP 25 295 333 0\n",
      "X $1GMSC.arff OBagAd 25 1709 1744 0\n",
      "X $1GMSC.arff OBagASHT 25 2263 1920 0\n",
      "X $1GMSC.arff OBag 25 2260 1832 0\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "\n",
      "esize 25\n",
      "bsize 50\n",
      "with incremental: True\n",
      "\n",
      "X $1elecNormNew.arff ARF 50 316 467 778\n",
      "X $1elecNormNew.arff LBag 50 524 693 1143\n",
      "X $1elecNormNew.arff SRP 50 169 249 376\n",
      "X $1elecNormNew.arff OBagAd 50 1208 1171 2255\n",
      "X $1elecNormNew.arff OBagASHT 50 1496 1358 2619\n",
      "X $1elecNormNew.arff OBag 50 1664 1395 2733\n",
      "X $1covtypeNorm.arff ARF 50 207 401 586\n",
      "X $1covtypeNorm.arff LBag 50 150 297 442\n",
      "X $1covtypeNorm.arff SRP 50 68 120 163\n",
      "X $1covtypeNorm.arff OBagAd 50 283 422 610\n",
      "X $1covtypeNorm.arff OBagASHT 50 251 419 701\n",
      "X $1covtypeNorm.arff OBag 50 288 432 699\n",
      "X $1airlines.arff ARF 50 66 160 145\n",
      "X $1airlines.arff LBag 50 46 153 151\n",
      "X $1airlines.arff SRP 50 69 153 177\n",
      "X $1airlines.arff OBagAd 50 170 252 457\n",
      "X $1airlines.arff OBagASHT 50 177 575 901\n",
      "X $1airlines.arff OBag 50 170 990 1073\n",
      "X $1GMSC.arff ARF 50 540 684 1255\n",
      "X $1GMSC.arff LBag 50 716 850 1351\n",
      "X $1GMSC.arff SRP 50 295 333 621\n",
      "X $1GMSC.arff OBagAd 50 1709 1744 3915\n",
      "X $1GMSC.arff OBagASHT 50 2263 1920 4155\n",
      "X $1GMSC.arff OBag 50 2260 1832 3934\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "\n",
      "esize 25\n",
      "bsize 100\n",
      "with incremental: True\n",
      "\n",
      "X $1elecNormNew.arff ARF 100 316 467 0\n",
      "X $1elecNormNew.arff LBag 100 524 693 0\n",
      "X $1elecNormNew.arff SRP 100 169 249 0\n",
      "X $1elecNormNew.arff OBagAd 100 1208 1171 0\n",
      "X $1elecNormNew.arff OBagASHT 100 1496 1358 0\n",
      "X $1elecNormNew.arff OBag 100 1664 1395 0\n",
      "X $1covtypeNorm.arff ARF 100 207 401 0\n",
      "X $1covtypeNorm.arff LBag 100 150 297 0\n",
      "X $1covtypeNorm.arff SRP 100 68 120 0\n",
      "X $1covtypeNorm.arff OBagAd 100 283 422 0\n",
      "X $1covtypeNorm.arff OBagASHT 100 251 419 0\n",
      "X $1covtypeNorm.arff OBag 100 288 432 0\n",
      "X $1airlines.arff ARF 100 66 160 0\n",
      "X $1airlines.arff LBag 100 46 153 0\n",
      "X $1airlines.arff SRP 100 69 153 0\n",
      "X $1airlines.arff OBagAd 100 170 252 0\n",
      "X $1airlines.arff OBagASHT 100 177 575 0\n",
      "X $1airlines.arff OBag 100 170 990 0\n",
      "X $1GMSC.arff ARF 100 540 684 0\n",
      "X $1GMSC.arff LBag 100 716 850 0\n",
      "X $1GMSC.arff SRP 100 295 333 0\n",
      "X $1GMSC.arff OBagAd 100 1709 1744 0\n",
      "X $1GMSC.arff OBagASHT 100 2263 1920 0\n",
      "X $1GMSC.arff OBag 100 2260 1832 0\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "\n",
      "esize 25\n",
      "bsize 500\n",
      "with incremental: True\n",
      "\n",
      "X $1elecNormNew.arff ARF 500 316 467 798\n",
      "X $1elecNormNew.arff LBag 500 524 693 1317\n",
      "X $1elecNormNew.arff SRP 500 169 249 419\n",
      "X $1elecNormNew.arff OBagAd 500 1208 1171 2594\n",
      "X $1elecNormNew.arff OBagASHT 500 1496 1358 2988\n",
      "X $1elecNormNew.arff OBag 500 1664 1395 2924\n",
      "X $1covtypeNorm.arff ARF 500 207 401 616\n",
      "X $1covtypeNorm.arff LBag 500 150 297 511\n",
      "X $1covtypeNorm.arff SRP 500 68 120 162\n",
      "X $1covtypeNorm.arff OBagAd 500 283 422 761\n",
      "X $1covtypeNorm.arff OBagASHT 500 251 419 794\n",
      "X $1covtypeNorm.arff OBag 500 288 432 756\n",
      "X $1airlines.arff ARF 500 66 160 165\n",
      "X $1airlines.arff LBag 500 46 153 170\n",
      "X $1airlines.arff SRP 500 69 153 189\n",
      "X $1airlines.arff OBagAd 500 170 252 448\n",
      "X $1airlines.arff OBagASHT 500 177 575 836\n",
      "X $1airlines.arff OBag 500 170 990 1162\n",
      "X $1GMSC.arff ARF 500 540 684 1261\n",
      "X $1GMSC.arff LBag 500 716 850 1647\n",
      "X $1GMSC.arff SRP 500 295 333 535\n",
      "X $1GMSC.arff OBagAd 500 1709 1744 4110\n",
      "X $1GMSC.arff OBagASHT 500 2263 1920 4911\n",
      "X $1GMSC.arff OBag 500 2260 1832 4669\n",
      "\n",
      "\n",
      "\n",
      "--------------------\n",
      "\n",
      "esize 25\n",
      "bsize 2000\n",
      "with incremental: True\n",
      "\n",
      "X $1elecNormNew.arff ARF 2000 316 467 710\n",
      "X $1elecNormNew.arff LBag 2000 524 693 1269\n",
      "X $1elecNormNew.arff SRP 2000 169 249 392\n",
      "X $1elecNormNew.arff OBagAd 2000 1208 1171 2440\n",
      "X $1elecNormNew.arff OBagASHT 2000 1496 1358 2823\n",
      "X $1elecNormNew.arff OBag 2000 1664 1395 2795\n",
      "X $1covtypeNorm.arff ARF 2000 207 401 586\n",
      "X $1covtypeNorm.arff LBag 2000 150 297 471\n",
      "X $1covtypeNorm.arff SRP 2000 68 120 160\n",
      "X $1covtypeNorm.arff OBagAd 2000 283 422 613\n",
      "X $1covtypeNorm.arff OBagASHT 2000 251 419 733\n",
      "X $1covtypeNorm.arff OBag 2000 288 432 731\n",
      "X $1airlines.arff ARF 2000 66 160 179\n",
      "X $1airlines.arff LBag 2000 46 153 182\n",
      "X $1airlines.arff SRP 2000 69 153 160\n",
      "X $1airlines.arff OBagAd 2000 170 252 616\n",
      "X $1airlines.arff OBagASHT 2000 177 575 923\n",
      "X $1airlines.arff OBag 2000 170 990 1132\n",
      "X $1GMSC.arff ARF 2000 540 684 1061\n",
      "X $1GMSC.arff LBag 2000 716 850 1672\n",
      "X $1GMSC.arff SRP 2000 295 333 572\n",
      "X $1GMSC.arff OBagAd 2000 1709 1744 3810\n",
      "X $1GMSC.arff OBagASHT 2000 2263 1920 4572\n",
      "X $1GMSC.arff OBag 2000 2260 1832 4520\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/reginaldoluisdeluna/Documents/Ufscar/comparison-xue3m-minibatching/\n",
    "\n",
    "for i in range(len(moaDumpFolders)):\n",
    "    architecture=moaDumpFolders[i].split('/')[0]\n",
    "    print(f\"------------------------------ {architecture} ------------------------------ \")\n",
    "    parse_folder_to_file(f\"{moaDumpFolders[i]}\", f\"parsed_csvs/{wantedCSVfilename[i]}\")\n",
    "    calculate_rate_csv(f'parsed_csvs/{wantedCSVfilename[i]}', architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
